{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "IaOsje3-8Mk0"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***One-Class Sub-Network Analysis***\n",
        "*(Vowel Phonemes Binary Classifier)*\n",
        "\n",
        "**Author:** S. Giacomelli\n",
        "\n",
        "**Year:** 2023\n",
        "\n",
        "**Affiliation:** A.Casella Conservatory (student)\n",
        "\n",
        "**Master Degree Thesis**: \"*Vowel phonemes Analysis & Classification by means of OCON rectifiers Deep Learning Architectures*\"\n",
        "\n",
        "**Description:** Python scripts for \"One-Class\" neural network binary classifier analysis and optimization"
      ],
      "metadata": {
        "id": "JTsmbLJsqeaf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "251yX4LgHb_U"
      },
      "outputs": [],
      "source": [
        "# Numerical computations packages/modules\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Dataset processing modules\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Graphic visualization modules\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib_inline\n",
        "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n",
        "\n",
        "# Common Seed initialization\n",
        "SEED = 42  # ... the answer to the ultimate question of Life, the Universe, and Everything... (cit.)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **HGCW Dataset** One-Hot Encoding\n",
        "(class binarization)"
      ],
      "metadata": {
        "id": "PdGLB754IcY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "HGCW_dataset_utils = np.load(file='./HGCW_dataset_utils.npz')\n",
        "print('Raw features                    Data shape:', HGCW_dataset_utils['HGCW_raw'].shape)\n",
        "print('Fundamental Normalized features Data shape:', HGCW_dataset_utils['HGCW_fund_norm'].shape)\n",
        "print('MinMax features                 Data shape:', HGCW_dataset_utils['HGCW_minmax'].shape)\n",
        "print('Labels                          Data shape:', HGCW_dataset_utils['HGCW_labels'].shape)\n",
        "print('Classes size                    Data shape:', HGCW_dataset_utils['classes_size'].shape)\n",
        "print('Classes indices                 Data shape:', HGCW_dataset_utils['classes_idx'].shape)\n",
        "\n",
        "x_data_raw_np = HGCW_dataset_utils['HGCW_raw']\n",
        "x_data_fund_norm = HGCW_dataset_utils['HGCW_fund_norm']\n",
        "x_data_minmax = HGCW_dataset_utils['HGCW_minmax']\n",
        "y_labels_raw_np = HGCW_dataset_utils['HGCW_labels']\n",
        "vow_size = HGCW_dataset_utils['classes_size']\n",
        "end_idx = HGCW_dataset_utils['classes_idx']\n",
        "\n",
        "# Auxiliary lists\n",
        "vowels = ['ae', 'ah', 'aw', 'eh', 'er', 'ei', 'ih', 'iy', 'oa', 'oo', 'uh', 'uw']  # Vowels list\n",
        "colors = ['red', 'saddlebrown', 'darkorange', 'darkgoldenrod', 'gold', 'darkkhaki', 'olive', 'darkgreen', 'steelblue', 'fuchsia', 'indigo', 'black']"
      ],
      "metadata": {
        "id": "ENVQj6i8YmG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Class-specific One-hot encoding (Binarization)\n",
        "def one_hot_encoder(sel_class_number: int = 3, dataset: np.ndarray = x_data_minmax, orig_labels: int = len(vowels), classes_size: list = vow_size, classes_idx: list = end_idx, debug=False):\n",
        "\n",
        "    classes = [n for n in range(orig_labels)]  # Class Labels list initialization\n",
        "\n",
        "    # Auxiliary Parameters Initialization\n",
        "    if sel_class_number < len(classes):\n",
        "        classes.remove(sel_class_number)  # REST Classes list\n",
        "        if debug is True:\n",
        "            print(f'Selected Class \"{vowels[sel_class_number]}\" : {classes_size[sel_class_number]} samples')\n",
        "        sub_classes_size = classes_size[sel_class_number] // len(classes)\n",
        "        if debug is True:\n",
        "            print(f'Rest Classes size (...each): {sub_classes_size} samples')\n",
        "\n",
        "        # 1-Subset processing\n",
        "        sub_data = dataset[classes_idx[sel_class_number]: classes_idx[sel_class_number + 1], :]  # Selected Class feature slicing\n",
        "        sub_data_labels_bin = np.ones((classes_size[sel_class_number], 1), dtype='int')  # Selected Class labels (1) creation\n",
        "        sub_data_labels = np.ones((classes_size[sel_class_number], 1), dtype='int') * sel_class_number\n",
        "\n",
        "        # 0-Subset processing\n",
        "        for i in classes:\n",
        "            class_i_indices = np.random.choice(np.arange(classes_idx[i], classes_idx[i + 1], 1), size=sub_classes_size, replace=False)\n",
        "            sub_class_i_array = dataset[class_i_indices, :]\n",
        "            sub_class_labels_bin_array = np.zeros((sub_class_i_array.shape[0], 1), dtype='int')  # Rest I-esimal Class labels (0) creation\n",
        "            sub_class_labels_array = np.ones((sub_class_i_array.shape[0], 1), dtype='int') * i\n",
        "\n",
        "            # Outputs append\n",
        "            sub_data = np.vstack((sub_data, sub_class_i_array))\n",
        "            sub_data_labels_bin = np.vstack((sub_data_labels_bin, sub_class_labels_bin_array))\n",
        "            sub_data_labels = np.vstack((sub_data_labels, sub_class_labels_array))\n",
        "    else:\n",
        "        raise ValueError(f'Invalid Class ID: \"{sel_class_number}\" --> It must be less than {len(classes)}!')\n",
        "\n",
        "    return sub_data, sub_data_labels_bin, sub_data_labels\n",
        "\n",
        "# Test Call\n",
        "dataset = x_data_minmax\n",
        "sel_class_number = 0\n",
        "sub_data, sub_data_labels_bin, sub_data_labels = one_hot_encoder(sel_class_number=sel_class_number, dataset=dataset, debug=True)\n",
        "diff_labels_bin = len(np.unique(sub_data_labels_bin))\n",
        "print('--------------------------------')\n",
        "print(f\"SUB'Min-Max' Normalized Dataset: {sub_data.shape[0]} elements (w. {diff_labels_bin} BINARIZED labels) & {sub_data.shape[1]} features each\")\n",
        "print(f'Also AVAILABLE Standard Labels: {sub_data_labels.shape[0]} samples (w. {len(np.unique(sub_data_labels))} labels)')"
      ],
      "metadata": {
        "id": "eewbU7eHQZrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sub-Dataset Plot (previous example)\n",
        "classes = [n for n in range(len(vowels))]\n",
        "sub_classes_size = vow_size[sel_class_number] // (len(classes) - 1)\n",
        "\n",
        "plt.figure(figsize=(12, 15))\n",
        "plt.suptitle(f'Sub-Dataset ({vowels[sel_class_number]} - example) One-Hot Encoding')\n",
        "\n",
        "counter = 0\n",
        "for index in classes:\n",
        "    if index == sel_class_number:  # Selected Class exception (non increment counter variable)\n",
        "        first_coords = sub_data[0: vow_size[sel_class_number], 1]\n",
        "        second_coords = sub_data[0: vow_size[sel_class_number], 2]\n",
        "        third_coords = sub_data[0: vow_size[sel_class_number], 3]\n",
        "    else:\n",
        "        start = vow_size[sel_class_number] + (counter * sub_classes_size)\n",
        "        end = start + sub_classes_size\n",
        "\n",
        "        first_coords = sub_data[start : end, 1]\n",
        "        second_coords = sub_data[start : end, 2]\n",
        "        third_coords = sub_data[start : end, 3]\n",
        "\n",
        "        counter +=1\n",
        "\n",
        "    plt.subplot(3, 2, 1)\n",
        "    plt.title('$1_{st}$ VS $2_{nd}$')\n",
        "    plt.scatter(first_coords, second_coords, marker='o', color=colors[index], label=f'Vowel \"{vowels[index]}\"')\n",
        "    plt.xlabel('$1_{st}$ Formant Ratio')\n",
        "    plt.ylabel('$2_{nd}$ Formant Ratio')\n",
        "    plt.legend(loc='best')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.subplot(3, 2, 3)\n",
        "    plt.title('$1_{st}$ VS $3_{rd}$')\n",
        "    plt.scatter(first_coords, third_coords, marker='o', color=colors[index], label=f'Vowel \"{vowels[index]}\"')\n",
        "    plt.xlabel('$1_{st}$ Formant Ratio')\n",
        "    plt.ylabel('$3_{rd}$ Formant Ratio')\n",
        "    plt.legend(loc='best')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.subplot(3, 2, 5)\n",
        "    plt.title('$2_{nd}$ VS $3_{rd}$')\n",
        "    plt.scatter(second_coords, third_coords, marker='o', color=colors[index], label=f'Vowel \"{vowels[index]}\"')\n",
        "    plt.xlabel('$2_{nd}$ Formant Ratio')\n",
        "    plt.ylabel('$3_{rd}$ Formant Ratio')\n",
        "    plt.legend(loc='best')\n",
        "    plt.grid(True)\n",
        "\n",
        "plt.subplot(3, 2, 2)\n",
        "plt.title('$1_{st}$ VS $2_{nd}$ Binarized')\n",
        "plt.scatter(sub_data[0: vow_size[sel_class_number], 1], sub_data[0: vow_size[sel_class_number], 2], color=colors[sel_class_number], label=f'Vowel \"{vowels[sel_class_number]}\"')\n",
        "plt.scatter(sub_data[vow_size[sel_class_number]:, 1], sub_data[vow_size[sel_class_number]:, 2], color='grey', label=f'Rest')\n",
        "plt.xlabel('$1_{st}$ Formant Ratio')\n",
        "plt.ylabel('$2_{nd}$ Formant Ratio')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(3, 2, 4)\n",
        "plt.title('$1_{st}$ VS $3_{rd}$ Binarized')\n",
        "plt.scatter(sub_data[0: vow_size[sel_class_number], 1], sub_data[0: vow_size[sel_class_number], 3], color=colors[sel_class_number], label=f'Vowel \"{vowels[sel_class_number]}\"')\n",
        "plt.scatter(sub_data[vow_size[sel_class_number]:, 1], sub_data[vow_size[sel_class_number]:, 3], color='grey', label=f'Rest')\n",
        "plt.xlabel('$1_{st}$ Formant Ratio')\n",
        "plt.ylabel('$3_{rd}$ Formant Ratio')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(3, 2, 6)\n",
        "plt.title('$2_{nd}$ VS $3_{rd}$ Binarized')\n",
        "plt.scatter(sub_data[0: vow_size[sel_class_number], 2], sub_data[0: vow_size[sel_class_number], 3], color=colors[sel_class_number], label=f'Vowel \"{vowels[sel_class_number]}\"')\n",
        "plt.scatter(sub_data[vow_size[sel_class_number]:, 2], sub_data[vow_size[sel_class_number]:, 3], color='grey', label=f'Rest')\n",
        "plt.xlabel('$2_{nd}$ Formant Ratio')\n",
        "plt.ylabel('$3_{rd}$ Formant Ratio')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{vowels[sel_class_number]}_class_one_hot_encoding')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AleZoZ3FmvP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train/Test split (auxiliary function)\n",
        "def train_test_split_aux(features_dataset, labels_dataset, test_perc, tolerance):\n",
        "    \"\"\"\n",
        "    An auxiliary Train_Test_split function (based on Scikit Learn implementation) w. balance tolerance specification\n",
        "    \"\"\"\n",
        "    test_size = int(test_perc / 100 * len(features_dataset))\n",
        "    train_balance = 0  # Output Training set balance value initialization\n",
        "    test_balance = 0  # Output Testing set balance value initialization\n",
        "\n",
        "    min_tol = np.mean(labels_dataset) - tolerance\n",
        "    max_tol = np.mean(labels_dataset) + tolerance\n",
        "    print(f'Data Balancing  (TARGET = {np.mean(labels_dataset)} +- {tolerance}): ', end='')\n",
        "\n",
        "    while (min_tol >= train_balance or train_balance >= max_tol) or (min_tol >= test_balance or test_balance >= max_tol):\n",
        "        train_data, test_data, train_labels, test_labels = train_test_split(features_dataset, labels_dataset, test_size=test_size, shuffle=True)\n",
        "        train_balance = np.mean(train_labels)\n",
        "        test_balance = np.mean(test_labels)\n",
        "        print('.', end='')\n",
        "    else:\n",
        "        print('OK')\n",
        "\n",
        "    return train_data, test_data, train_labels, test_labels, train_balance, test_balance\n",
        "\n",
        "# Train-Dev-Test split function\n",
        "def train_dev_test_split(x_data, y_labels, split_list, tolerance=0.1, output='Loaders', debug=False):\n",
        "    \"\"\"\n",
        "    Compute a Train, Development (Hold-Out) and a Test set split w. PyTorch Dataset conversion (and eventual Loaders initialization)\n",
        "    \"\"\"\n",
        "    if len(split_list) == 3:\n",
        "        # Train - Dev+Test separation\n",
        "        print('Training --- Devel/Test SPLIT')\n",
        "        train_data, testTMP_data, train_labels, testTMP_labels, _, _ = train_test_split_aux(x_data, y_labels, (split_list[1] * 100) + (split_list[2] * 100), tolerance)\n",
        "        print('----------------------------------')\n",
        "\n",
        "        # Dev - Test separation\n",
        "        print('Devel    ---     Test SPLIT')\n",
        "\n",
        "        split = ((split_list[1] * 100) / np.sum(split_list[1:] * 100)) * 100  # Split in %\n",
        "        dev_data, test_data, dev_labels, test_labels, _, _ = train_test_split_aux(testTMP_data, testTMP_labels, split, tolerance)\n",
        "        print('----------------------------------')\n",
        "\n",
        "        # Tensor Conversion\n",
        "        train_data_tensor = torch.tensor(train_data).float()\n",
        "        train_labels_tensor = torch.tensor(train_labels, dtype=torch.int64).squeeze()\n",
        "        dev_data_tensor = torch.tensor(dev_data).float()\n",
        "        dev_labels_tensor = torch.tensor(dev_labels, dtype=torch.int64).squeeze()\n",
        "        test_data_tensor = torch.tensor(test_data).float()\n",
        "        test_labels_tensor = torch.tensor(test_labels, dtype=torch.int64).squeeze()\n",
        "        if debug is True:\n",
        "            print(f'Training Data        Shape: {train_data.shape}')\n",
        "            print(f'Development Data     Shape: {dev_data.shape}')\n",
        "            print(f'Testing Data         Shape: {test_data.shape}')\n",
        "\n",
        "            # Balance Evaluation\n",
        "            print(f'Training Set       Balance: {np.mean(train_labels)}')\n",
        "            print(f'Development Set    Balance: {np.mean(dev_labels)}')\n",
        "            print(f'Testing Set        Balance: {np.mean(test_labels)}')\n",
        "\n",
        "        if output != 'Loaders':\n",
        "            return train_data_tensor, train_labels_tensor, dev_data_tensor, dev_labels_tensor, test_data_tensor, test_labels_tensor\n",
        "        else:\n",
        "            # PyTorch Dataset Conversion\n",
        "            train_dataset = torch.utils.data.TensorDataset(torch.tensor(train_data).float(), torch.tensor(train_labels, dtype=torch.int64).squeeze())\n",
        "            dev_dataset = torch.utils.data.TensorDataset(torch.tensor(dev_data).float(), torch.tensor(dev_labels, dtype=torch.int64).squeeze())\n",
        "            test_dataset = torch.utils.data.TensorDataset(torch.tensor(test_data).float(), torch.tensor(test_labels, dtype=torch.int64).squeeze())\n",
        "\n",
        "            # DataLoader (Batches) --> Drop-Last control to optimize training\n",
        "            trainLoader = DataLoader(train_dataset, shuffle=False, batch_size = 32, drop_last=True)\n",
        "            devLoader = DataLoader(dev_dataset, shuffle=False, batch_size = dev_dataset.tensors[0].shape[0])\n",
        "            testLoader = DataLoader(test_dataset, shuffle=False, batch_size = test_dataset.tensors[0].shape[0])\n",
        "            if debug is True:\n",
        "                print(f'Training Set    Batch Size: {trainLoader.batch_size}')\n",
        "                print(f'Development Set Batch Size: {devLoader.batch_size}')\n",
        "                print(f'Testing Set     Batch Size: {testLoader.batch_size}')\n",
        "\n",
        "            return trainLoader, devLoader, testLoader\n",
        "    else:\n",
        "        # Train - Test separation\n",
        "        print('Training --- Test    SPLIT')\n",
        "        train_data, test_data, train_labels, test_labels, _, _ = train_test_split_aux(x_data, y_labels, split_list[1] * 100, tolerance, debug=debug)\n",
        "        print('--------------------------')\n",
        "\n",
        "        # Tensor Conversion\n",
        "        train_data_tensor = torch.tensor(train_data).float()\n",
        "        train_labels_tensor = torch.tensor(train_labels, dtype=torch.int64).squeeze()\n",
        "        test_data_tensor = torch.tensor(test_data).float()\n",
        "        test_labels_tensor = torch.tensor(test_labels, dtype=torch.int64).squeeze()\n",
        "        if debug is True:\n",
        "            print(f'Training Data        Shape: {train_data.shape}')\n",
        "            print(f'Testing Data         Shape: {test_data.shape}')\n",
        "\n",
        "            # Balance Evaluation\n",
        "            print(f'Training Set    Balance: {np.mean(train_labels)}')\n",
        "            print(f'Testing Set     Balance: {np.mean(test_labels)}')\n",
        "\n",
        "        if output != 'Loaders':\n",
        "            return train_data_tensor, train_labels_tensor, test_data_tensor, test_labels_tensor\n",
        "        else:\n",
        "            # PyTorch Dataset Conversion\n",
        "            train_dataset = torch.utils.data.TensorDataset(torch.tensor(train_data).float(), torch.tensor(train_labels, dtype=torch.int64).squeeze())\n",
        "            test_dataset = torch.utils.data.TensorDataset(torch.tensor(test_data).float(), torch.tensor(test_labels, dtype=torch.int64).squeeze())\n",
        "\n",
        "            # DataLoader (Batches) --> Drop-Last control to optimize training\n",
        "            trainLoader = DataLoader(train_dataset, shuffle=False, batch_size = 32, drop_last=True)\n",
        "            testLoader = DataLoader(test_dataset, shuffle=False, batch_size = test_dataset.tensors[0].shape[0])\n",
        "            if debug is True:\n",
        "                print(f'Training Set    Batch Size: {trainLoader.batch_size}')\n",
        "                print(f'Testing Set     Batch Size: {testLoader.batch_size}')\n",
        "\n",
        "            return trainLoader, testLoader"
      ],
      "metadata": {
        "id": "-I3fffThJo6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Multi-Layer Perceptron Binary Classifier**"
      ],
      "metadata": {
        "id": "QCg17wUYIexx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dynamic Multi-Layer Architecture Class (w. units and activation function specification)\n",
        "class binaryClassifier(nn.Module):                                              # nn.Module: base class to inherit from\n",
        "    def __init__(self, n_layers, n_units, act_fun):                             # self + attributes (architecture hyper-parameters)\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = nn.ModuleDict()                                           # Dictionary to store Model layers\n",
        "        self.nLayers = n_layers                                                 # Class instance parameter\n",
        "\n",
        "        # Input Layer\n",
        "        if n_layers == 1:\n",
        "            self.layers['input'] = nn.Linear(3, n_units)                        # Key 'input' layer specification\n",
        "\n",
        "        else:\n",
        "            self.layers['input'] = nn.Linear(3, n_units[0])\n",
        "\n",
        "\n",
        "        # Hidden Layers\n",
        "        if n_layers == 1:\n",
        "            self.layers[f'hidden0'] = nn.Linear(n_units, n_units)\n",
        "        else:\n",
        "            for i in range(n_layers):\n",
        "                if i == (n_layers - 1):\n",
        "                    self.layers[f'hidden{i}'] = nn.Linear(n_units[i], n_units[i])\n",
        "                else:\n",
        "                    self.layers[f'hidden{i}'] = nn.Linear(n_units[i], n_units[i + 1])\n",
        "\n",
        "        # Output Layer\n",
        "        if n_layers == 1:\n",
        "            self.layers['output'] = nn.Linear(n_units, 1)                       # Key 'output' layer specification\n",
        "        else:\n",
        "            self.layers['output'] = nn.Linear(n_units[n_layers - 1], 1)\n",
        "\n",
        "        # Activation Function\n",
        "        self.actfun = act_fun                                                   # Function string-name attribute association\n",
        "\n",
        "        # Weights initialization (Kaiming He - Normal Distributed)\n",
        "        for layer in self.layers.keys():\n",
        "            nn.init.kaiming_normal_(self.layers[layer].weight, mode='fan_in')\n",
        "\n",
        "    # Forward Pass Method\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Activation function object computation\n",
        "        actfun = getattr(torch.nn, self.actfun)\n",
        "\n",
        "        # Input Layer pass                                                      --> Weightening (Dot Product) \"Linear transform\" + \"Non linear function\" transform application\n",
        "        x = actfun()(self.layers['input'](x))\n",
        "\n",
        "        # Hidden Layers sequential pass                                         --> Weightening (Dot Product) \"Linear transform\" + \"Non linear function\" transform application\n",
        "        for i in range(self.nLayers):\n",
        "            x = actfun()(self.layers[f'hidden{i}'](x))\n",
        "\n",
        "        # Output Layer pass                                                     --> Output Weightening (Dot Product) \"Linear transform\" (Optimizer implement an Output Sigmoid sctivation)\n",
        "        x = self.layers['output'](x)\n",
        "        x = nn.Sigmoid()(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "Krb98UvhIhpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train/Test function (w. variable Backpropagation Optimizer Algorithm definition)\n",
        "def cross_val_train_test(model, optim: str, epochs: int, learning_rate, train_data: torch.Tensor, train_labels: torch.Tensor, test_data: torch.Tensor, test_labels: torch.Tensor, debug: bool = False):\n",
        "    \"\"\"\n",
        "    Train & Test an ANN Classifier w. Binary Cross Entropy Loss computation and the specified Backpropagation Optimizer algorithm\n",
        "    \"\"\"\n",
        "    # Loss Function initialization\n",
        "    loss_function = nn.BCELoss()\n",
        "\n",
        "    # Optimizer Algorithm initialization\n",
        "    optimizer_function = getattr(torch.optim, optim)  # Optimizer function retrieving\n",
        "    optimizer = optimizer_function(model.parameters(), lr=learning_rate)  # Parameters application (rest are standard initialized)\n",
        "\n",
        "    # TRAINING Phase\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "\n",
        "    model.train()  # TRAINING Switch ON\n",
        "\n",
        "    for i in range(epochs):\n",
        "        train_predictions = model(train_data)\n",
        "        train_loss = loss_function(train_predictions.squeeze(), train_labels.squeeze().to(torch.float))\n",
        "        train_losses.append(train_loss.detach())\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_accuracy = 100 * torch.mean(((train_predictions.squeeze() > 0.5) == train_labels.squeeze()).float())\n",
        "        train_accuracies.append(train_accuracy.detach())\n",
        "\n",
        "        if debug is True:\n",
        "            if i % 100 == 0:\n",
        "                print(f'Epoch {i} --> Train Accuracy: {train_accuracy.detach()}%')\n",
        "                print('-------------------------')\n",
        "\n",
        "    # TESTING Phase\n",
        "    model.eval()  # EVALUATION Switch ON (TRAINING Switch OFF)\n",
        "    with torch.no_grad():  # Gradient (and Batch Normalization) deactivation\n",
        "        test_predictions = model(test_data)\n",
        "        test_accuracy = 100 * torch.mean(((test_predictions.squeeze() > 0.5) == test_labels.squeeze()).float())\n",
        "\n",
        "        if debug is True:\n",
        "            print(f'TEST ACCURACY: {test_accuracy.detach()} %')\n",
        "            print('-------------------------')\n",
        "\n",
        "    return test_predictions.detach(), test_accuracy.detach(), train_losses, train_accuracies\n",
        "\n",
        "# Batch Training function\n",
        "def mini_batch_train_test(model, optim: str, epochs: int, learning_rate, train_loader, dev_loader, test_loader, debug=False):\n",
        "    \"\"\"\n",
        "    Train & Test an ANN Architecture via Mini-Batch Training (w. Train/Dev/Test PyTorch Loaders) and same params of cross_valid_train_test\n",
        "    \"\"\"\n",
        "    # Loss Function initialization\n",
        "    loss_function = nn.BCELoss()\n",
        "\n",
        "    # Optimizer Algorithm initialization\n",
        "    optimizer_function = getattr(torch.optim, optim)\n",
        "    optimizer = optimizer_function(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Output list initialization\n",
        "    train_accuracies = []\n",
        "    train_losses = []\n",
        "    dev_accuracies = []\n",
        "\n",
        "    # TRAINING Phase\n",
        "    for epoch in range(epochs):\n",
        "        model.train()  # TRAINING Switch ON\n",
        "\n",
        "        batch_accuracies = []\n",
        "        batch_losses = []\n",
        "\n",
        "        # Training BATCHES Loop\n",
        "        for data_batch, labels_batch in train_loader:\n",
        "            train_predictions = model(data_batch)\n",
        "            train_loss = loss_function(train_predictions.squeeze(), labels_batch.type(torch.int64).float())\n",
        "            batch_losses.append(train_loss.detach())\n",
        "\n",
        "            # Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Accuracy\n",
        "            train_accuracy = 100 * torch.mean(((train_predictions.squeeze() > 0.5) == labels_batch.type(torch.int64).squeeze()).float())\n",
        "\n",
        "            # Batch Stats appending\n",
        "            batch_accuracies.append(train_accuracy.detach())\n",
        "            batch_losses.append(train_loss.detach())\n",
        "\n",
        "        # Training Stats appending\n",
        "        train_accuracies.append(np.mean(batch_accuracies))  # Average of Batch Accuracies = Training step accuracy\n",
        "        train_losses.append(np.mean(batch_losses))  # Average of Batch Losses = Training step Losses\n",
        "\n",
        "        # EVALUATION (Dev) Phase\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            dev_data_batch, dev_labels_batch = next(iter(dev_loader))\n",
        "            dev_predictions = model(dev_data_batch)\n",
        "\n",
        "            dev_accuracy = 100 * torch.mean(((dev_predictions.squeeze() > 0.5) == dev_labels_batch.type(torch.int64).squeeze()).float())\n",
        "\n",
        "            if debug is True:\n",
        "                if epoch % 100 == 0:\n",
        "                    print(f'Epoch {epoch} --> DEV ACCURACY: {dev_accuracy.detach():.3f} %')\n",
        "                    print('--------------------------------')\n",
        "\n",
        "            # Evaluation accuracy appending\n",
        "            dev_accuracies.append(dev_accuracy.detach())\n",
        "\n",
        "    # TEST Phase\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_data_batch, test_labels_batch = next(iter(test_loader))\n",
        "        test_predictions = model(test_data_batch)\n",
        "        test_accuracy = 100 * torch.mean(((test_predictions.squeeze() > 0.5) == test_labels_batch.type(torch.int64).squeeze()).float())\n",
        "\n",
        "        if debug is True:\n",
        "            print(f'TEST ACCURACY: {test_accuracy.detach():.2f} %')\n",
        "            print('--------------------------------------------------------------------')\n",
        "\n",
        "    return train_accuracies, train_losses, dev_accuracies, test_accuracy.detach()"
      ],
      "metadata": {
        "id": "QTxupXXoOxMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Architecture** optimal *hyper-parameters* estimate\n",
        "\n",
        "*Grid-Search* (orders of magnitude)\n",
        "- **Hidden Layers**: $1$\n",
        "- **Hidden Nodes**: $(10, 50, 100)$\n",
        "- **Activation Function**: ReLU (*He standard distribution initialization*)\n",
        "\n",
        "K. He, X. Zhang, S. Ren, J. Sun (2015) - [Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification](https://arxiv.org/pdf/1502.01852.pdf)\n",
        "\n",
        "- **Learning Rates**: $(0.001, 0.0001, 0.00001)$\n",
        "- **Optimizers**: Adam, RMSprop\n",
        "\n",
        "---\n",
        "\n",
        "**Root Mean Square Propagation (RMSprop)**\n",
        "\n",
        "\\begin{align}\n",
        "    w_t \\leftarrow w_{t-1} - \\frac{\\eta}{\\sqrt{v_t + \\epsilon}}\\nabla L\n",
        "\\end{align}\n",
        "\n",
        "with\n",
        "\n",
        "\\begin{align}\n",
        "    v_t = (1 - \\beta)(\\nabla L)^2 + \\beta v_{t-1}\n",
        "\\end{align}\n",
        "\n",
        "Similar to *Momentum* conditioning, but applied to Learning Rate coefficient (instead to Loss function) according to Gradient magnitudes. For this reason we speak about *Dynamic Learning Rate*, where:\n",
        "\n",
        "- large gradients: implies small LR and smaller steps of minimization\n",
        "- small gradients ($0 < x < 1$) : implies very large steps of minimization\n",
        "\n",
        "$\\epsilon$ is a standard positive coefficient added to denominator to avoid division by $0$: usually $10^{-8}$\n",
        "\n",
        "---\n",
        "\n",
        "**Adaptive Momentum (Adam)**\n",
        "\n",
        "Probably nowadays best gradient optimizer:\n",
        "\n",
        "\\begin{align}\n",
        "    w_t \\leftarrow w_{t-1} - \\frac{\\eta}{\\sqrt{s_t + \\epsilon}}v_t\n",
        "\\end{align}\n",
        "\n",
        "with\n",
        "\n",
        "\\begin{align}\n",
        "    v_t = \\frac{(1 - \\beta_1)\\nabla L + \\beta_1 v_{t-1}}{1 - \\beta_{1}^{t}}\n",
        "\\end{align}\n",
        "\n",
        "\\begin{align}\n",
        "    s_t = \\frac{(1 - \\beta_2)(\\nabla L)^2 + \\beta_2 s_{t-1}}{1 - \\beta_{2}^{t}}\n",
        "\\end{align}\n",
        "\n",
        "A combined form of **Momentum** and **RMSprop** with a dampening normalization factor, learning epoch dependent.\n",
        "\n",
        "---\n",
        "\n",
        "Reference: [PyTorch Reference - torch.optim Algorithms](https://pytorch.org/docs/stable/optim.html#algorithms)"
      ],
      "metadata": {
        "id": "nBPos83cSkUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment Parameters\n",
        "epochs = 1000  # For each \"Batch-Set\"\n",
        "iterations = 3  # A total of 3000 Epochs of Training (3x Batch-Sub-Dataset shuffling)\n",
        "min_tolerance = 0.1 # ...for sub-dataset balancing\n",
        "\n",
        "# Architecture Hyper-Parameters\n",
        "hidden_layers = 1\n",
        "hidden_nodes = [10, 50, 100]\n",
        "act_fun = 'ReLU'\n",
        "learning_rates = [0.001, 0.0001, 0.00001]  # [10^-3, 10^-4, 10^-5]\n",
        "optimizers = ['Adam', 'RMSprop']"
      ],
      "metadata": {
        "id": "H0ibBCJQ1N5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AVG. Time 2h\n",
        "from time import perf_counter\n",
        "debug=False\n",
        "experiment_results = np.zeros((len(hidden_nodes), len(learning_rates), len(optimizers), 2))  # Output Matrix initialization (1st layer: Mean Test Accuracies, 2nd Layer: Training Times)\n",
        "\n",
        "exp_counter = 0\n",
        "for i in range(len(hidden_nodes)):\n",
        "    for j in range(len(learning_rates)):\n",
        "        for k in range(len(optimizers)):\n",
        "\n",
        "            exp_counter += 1 # Aux variable increment\n",
        "            print(f'Experiment {exp_counter}: Units (HL): {hidden_nodes[i]}, LR: {learning_rates[j]}, Optimizer: {optimizers[k]}')\n",
        "\n",
        "            test_accuracies = []  # List of Classes Test Accuracies (Re-initialized for each experiment)\n",
        "            training_times = []  # List of Classes Training Times (Re-initialized for each experiment)\n",
        "\n",
        "            # Experiment Routine\n",
        "            for w in range(len(vowels)):\n",
        "\n",
        "                # Reset Seed\n",
        "                torch.manual_seed(SEED)\n",
        "\n",
        "                # Create Classifier\n",
        "                binary_classifier = binaryClassifier(1, hidden_nodes[i], act_fun)\n",
        "\n",
        "                # Iterated (w. Batch-Sets shuffling) Training\n",
        "                start_timer = perf_counter()\n",
        "                for iteration in range(iterations):\n",
        "\n",
        "                    # Dataset processing\n",
        "                    sub_data, sub_data_labels_bin, _ = one_hot_encoder(sel_class_number=w, dataset=x_data_minmax, debug=debug)\n",
        "                    print('----------------------------------')\n",
        "                    trainLoader, devLoader, testLoader = train_dev_test_split(sub_data[:, 1:], sub_data_labels_bin, [0.7, 0.15, 0.15], tolerance=min_tolerance, output='Loaders', debug=debug)\n",
        "\n",
        "                    # Train/Test Architecture\n",
        "                    _, _, _, test_accuracy = mini_batch_train_test(binary_classifier, optimizers[k], epochs, learning_rates[j], trainLoader, devLoader, testLoader, debug)\n",
        "                    print(f'Sub-Net \"{vowels[w]}\" Partial-{iteration + 1} TEST ACCURACY: {test_accuracy:.2f}%')\n",
        "\n",
        "                stop_timer = perf_counter()\n",
        "\n",
        "                # Class Outputs append\n",
        "                test_accuracies.append(test_accuracy) # in %\n",
        "                training_times.append(stop_timer - start_timer) # in sec.\n",
        "                print('---------------------------------------------------------------------')\n",
        "\n",
        "            print(f'Classes MEAN ACCURACY: {np.mean(test_accuracies)}%')\n",
        "            print(f'Classes Mean Training Runtime: {np.mean(training_times)}sec.')\n",
        "\n",
        "            experiment_results[i, j, k, 0] = np.mean(test_accuracies)  # Average of 12 classes Accuracies\n",
        "            experiment_results[i, j, k, 1] = np.mean(training_times)  # Average of 12 classes Training Times\n",
        "\n",
        "            print('------------------------------------------------------------------------------------------------------')\n",
        "\n",
        "# Outputs Save\n",
        "np.savez_compressed(file='./architecture_grid_search',\n",
        "                    avg_test_accuracies=experiment_results[:, :, :, 0],\n",
        "                    avg_training_times=experiment_results[:, :, :, 1])"
      ],
      "metadata": {
        "id": "7byAcvJ52-Yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Architecture Grid-Search Experiment Plot\n",
        "experiment_data = np.load(file='./architecture_grid_search.npz')\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.suptitle('Architecture Hyper-Parameters Experiment\\n(average results across all classes)\\n')\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "counter = 1\n",
        "for i in range(experiment_data['avg_test_accuracies'].shape[0]):\n",
        "    for j in range(experiment_data['avg_test_accuracies'].shape[1]):\n",
        "        for k in range(experiment_data['avg_test_accuracies'].shape[2]):\n",
        "            if k == 1:\n",
        "                plt.bar(counter, experiment_data['avg_test_accuracies'][i, j, k], color='k', label=f'HN: {hidden_nodes[i]}, LR: {learning_rates[j]}')\n",
        "            else:\n",
        "                plt.bar(counter, experiment_data['avg_test_accuracies'][i, j, k], color='r', label=f'HN: {hidden_nodes[i]}, LR: {learning_rates[j]}')\n",
        "\n",
        "            counter += 1\n",
        "\n",
        "max_accuracy = np.max(experiment_data['avg_test_accuracies'])\n",
        "plt.axhline(max_accuracy, color='grey', linestyle='--')\n",
        "plt.title(f'Test Accuracies (RMSprop = Black, Adam = Red), Max.: {max_accuracy:.2f}%')\n",
        "plt.xlabel('Experiment Run (index)')\n",
        "plt.xticks([(n + 1) for n in range(18)], [(n + 1) for n in range(18)])\n",
        "plt.ylabel('Accuracy (in %)')\n",
        "plt.ylim([50, 100])\n",
        "plt.grid()\n",
        "plt.legend(loc='lower center', bbox_to_anchor=(0.5, -0.3), fancybox=True, shadow=True, ncol=6)\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "counter = 1\n",
        "for i in range(experiment_data['avg_training_times'].shape[0]):\n",
        "    for j in range(experiment_data['avg_training_times'].shape[1]):\n",
        "        for k in range(experiment_data['avg_training_times'].shape[2]):\n",
        "            if k == 1:\n",
        "                plt.bar(counter, experiment_data['avg_training_times'][i, j, k], color='k', label=f'HN: {hidden_nodes[i]}, LR: {learning_rates[j]}')\n",
        "\n",
        "            else:\n",
        "                plt.bar(counter, experiment_data['avg_training_times'][i, j, k], color='pink', label=f'HN: {hidden_nodes[i]}, LR: {learning_rates[j]}')\n",
        "\n",
        "            counter += 1\n",
        "\n",
        "plt.title('Training Times (RMSprop = Black, Adam = Pink)')\n",
        "plt.xlabel('Experiment Run (index)')\n",
        "plt.xticks([(n + 1) for n in range(18)], [(n + 1) for n in range(18)])\n",
        "plt.ylabel('Time (in sec.)')\n",
        "plt.ylim([20, 40])\n",
        "plt.grid()\n",
        "plt.legend(loc='lower center', bbox_to_anchor=(0.5, -0.3), fancybox=True, shadow=True, ncol=6)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('architecture_grid_search')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Cadd-klotFk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Best Test Accuracy inspection\n",
        "best_run_acc = experiment_data['avg_test_accuracies'][2, 1, 0]\n",
        "best_run_time = experiment_data['avg_training_times'][2, 1, 0]\n",
        "print(f'Run 15 (Adam Optimizer): {best_run_acc:.2f}% in {best_run_time:.2f}sec. (per class)')"
      ],
      "metadata": {
        "id": "iXUSJCUYQy0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Architecture Optimization**\n",
        "\n",
        "```\n",
        "Multi-Layer Perceptron\n",
        "- Input Layer: 3 features [formant ratios, min-max normalized]\n",
        "- Hidden Layer: 100 units\n",
        "- Output Layer: 1 normalized probability\n",
        "- Learning Rate: 0.0001 (10^-4)\n",
        "- Optimizer : Adam (Adaptive Momentum)\n",
        "\n",
        "- Mini-Batch Training:\n",
        "    . Re-iterated Sub-Dataset Shuffling\n",
        "    . Batch size = 32\n",
        "```\n",
        "\n",
        "- **Bias Initialization**: $0$\n",
        "- **Regularization**: DropOut, Batch-Normalization, L2 Loss Regularization"
      ],
      "metadata": {
        "id": "AgKoZDGEpwM9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **DropOut**\n",
        "\n",
        "Probabilistic method to \"mute\" (sparsing) learning inference of arbitrary nodes during each epoch. It aims to uniform learning patterns and avoid mnemonic recognition/association of data examples.\n",
        "\n",
        "- N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, R. Salakhutdinov (2014) - [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](https://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf)"
      ],
      "metadata": {
        "id": "mkpaMjNG8QoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dynamic Multi-Layer Architecture Class (w. units, activation function and DropOut Rate specification)\n",
        "class binaryClassifier_dropout(nn.Module):                                      # nn.Module: base class to inherit from\n",
        "    def __init__(self, n_layers, n_units, act_fun, rate_in, rate_hidden):       # self + attributes (architecture hyper-parameters)\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = nn.ModuleDict()                                           # Dictionary to store Model layers\n",
        "        self.nLayers = n_layers                                                 # Class instance parameter\n",
        "\n",
        "        # Input Layer\n",
        "        self.layers['input'] = nn.Linear(3, n_units)                            # Key 'input' layer specification\n",
        "\n",
        "        # Hidden Layers\n",
        "        self.layers[f'hidden'] = nn.Linear(n_units, n_units)\n",
        "\n",
        "        # Output Layer\n",
        "        self.layers['output'] = nn.Linear(n_units, 1)                           # Key 'output' layer specification\n",
        "\n",
        "        # Activation Function\n",
        "        self.actfun = act_fun                                                   # Function string-name attribute association\n",
        "\n",
        "        # Dropout Parameter\n",
        "        self.dr_in = rate_in\n",
        "        self.dr_hidden = rate_hidden\n",
        "\n",
        "        # Weights & Bias initialization\n",
        "        for layer in self.layers.keys():\n",
        "            nn.init.kaiming_normal_(self.layers[layer].weight, mode='fan_in')   # Kaiming He - Normal Distributed (ReLU specific)\n",
        "        for layer in self.layers.keys():\n",
        "            self.layers[layer].bias.data.fill_(0.)                              # Bias initialization\n",
        "\n",
        "    # Forward Pass Method\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Activation function object computation\n",
        "        actfun = getattr(torch.nn, self.actfun)\n",
        "\n",
        "        # Input Layer pass                                                      --> Weightening (Dot Product) \"Linear transform\" + \"Non linear function\" transform application\n",
        "        x = actfun()(self.layers['input'](x))\n",
        "        x = F.dropout(x, p=self.dr_in, training=self.training)                  # Activate DropOut only when Model Training == True\n",
        "\n",
        "        # Hidden Layers sequential pass                                         --> Weightening (Dot Product) \"Linear transform\" + \"Non linear function\" transform application\n",
        "        x = actfun()(self.layers[f'hidden'](x))\n",
        "        x = F.dropout(x, p=self.dr_hidden, training=self.training)              # Same as \"Input pass\"\n",
        "\n",
        "        # Output Layer pass                                                     --> Output Weightening (Dot Product) \"Linear transform\" (Optimizer implement an Output Sigmoid sctivation)\n",
        "        x = self.layers['output'](x)\n",
        "        x = nn.Sigmoid()(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "DxKY1BXYc33T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment Parameters\n",
        "epochs = 1000  # For each \"Batch-Set\"\n",
        "iterations = 6  # A total of 6000 Epochs of Training (6x Batch-Sub-Dataset shuffling) --> w. Early Stopping\n",
        "min_tolerance = 0.1 # ...for sub-dataset balancing\n",
        "\n",
        "# Architecture Hyper-Parameters\n",
        "hidden_layer = 1\n",
        "hidden_nodes = 100\n",
        "act_fun = 'ReLU'\n",
        "learning_rate = 0.0001  # 10^-4\n",
        "optimizer = 'Adam'\n",
        "\n",
        "# DropOut Regularization Parameters\n",
        "dropout_rates_in = [0.8, 0.9]\n",
        "dropout_rates_hidden = (np.arange(5) / 10.) + 0.5"
      ],
      "metadata": {
        "id": "v3KGKKS4fL83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AVG. Time 1h 30min\n",
        "from time import perf_counter\n",
        "debug=False\n",
        "experiment_results = np.zeros((len(dropout_rates_in), len(dropout_rates_hidden), 2))\n",
        "\n",
        "exp_counter = 0\n",
        "for i in range(len(dropout_rates_in)):\n",
        "    for j in range(len(dropout_rates_hidden)):\n",
        "        exp_counter += 1\n",
        "        print(f'Experiment {exp_counter}: DropOut Input: {dropout_rates_in[i]}, DropOut Hidden: {dropout_rates_hidden[j]}')\n",
        "\n",
        "        test_accuracies = []  # List of Classes Test Accuracies (Re-initialized for each experiment)\n",
        "        training_times = []  # List of Classes Training Times (Re-initialized for each experiment)\n",
        "\n",
        "        # Experiment Routine\n",
        "        for k in range(len(vowels)):\n",
        "\n",
        "            # Reset Seed\n",
        "            torch.manual_seed(SEED)\n",
        "\n",
        "            # Create Classifier\n",
        "            binary_classifier = binaryClassifier_dropout(1, hidden_nodes, act_fun, dropout_rates_in[i], dropout_rates_hidden[j])\n",
        "\n",
        "            # Iterated (w. Batch-Sets shuffling) Training\n",
        "            iteration = 0\n",
        "\n",
        "            start_timer = perf_counter()\n",
        "            while iteration < iterations:\n",
        "\n",
        "                # Dataset processing\n",
        "                sub_data, sub_data_labels_bin, _ = one_hot_encoder(sel_class_number=k, dataset=x_data_minmax, debug=debug)\n",
        "                print('----------------------------------')\n",
        "                trainLoader, devLoader, testLoader = train_dev_test_split(sub_data[:, 1:], sub_data_labels_bin, [0.7, 0.15, 0.15], tolerance=min_tolerance, output='Loaders', debug=debug)\n",
        "\n",
        "                # Train/Test Architecture\n",
        "                _, _, _, test_accuracy = mini_batch_train_test(binary_classifier, optimizer, epochs, learning_rate, trainLoader, devLoader, testLoader, debug)\n",
        "                print(f'Sub-Net \"{vowels[k]}\" Partial-{iteration + 1} TEST ACCURACY: {test_accuracy:.2f}%')\n",
        "\n",
        "                if test_accuracy > 93.67:  # If specific class instance overshot class mean accuracy\n",
        "                    iteration += 1\n",
        "                    print(f'Training STOP {iteration}--------------------')\n",
        "                    break  # Early stop\n",
        "\n",
        "                iteration += 1  # Go to next Batch training iteration\n",
        "\n",
        "            stop_timer = perf_counter()\n",
        "\n",
        "            # Class Outputs append\n",
        "            test_accuracies.append(test_accuracy) # in %\n",
        "            training_times.append(stop_timer - start_timer) # in sec.\n",
        "            print('---------------------------------------------------------------------')\n",
        "\n",
        "        print(f'Classes MEAN ACCURACY: {np.mean(test_accuracies)}%')\n",
        "        print(f'Classes Mean Training Runtime: {np.mean(training_times)}sec.')\n",
        "\n",
        "        experiment_results[i, j, 0] = np.mean(test_accuracies)  # Average of 12 classes Accuracies\n",
        "        experiment_results[i, j, 1] = np.mean(training_times)  # Average of 12 classes Training Times\n",
        "\n",
        "        print('------------------------------------------------------------------------------------------------------')\n",
        "\n",
        "# Outputs Save\n",
        "np.savez_compressed(file='./dropout_grid_search',\n",
        "                    avg_test_accuracies=experiment_results[:, :, 0],\n",
        "                    avg_training_times=experiment_results[:, :, 1])"
      ],
      "metadata": {
        "id": "wrCCI-UEgt2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DropOut Grid-Search Experiment Plot\n",
        "experiment_data = np.load(file='./dropout_grid_search.npz')\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.suptitle('Dropout Regularization Experiment\\n(average results across all classes)\\n')\n",
        "\n",
        "counter = 0\n",
        "plt.subplot(2, 1, 1)\n",
        "for i in range(experiment_data['avg_test_accuracies'].shape[0]):\n",
        "    for j in range(experiment_data['avg_test_accuracies'].shape[1]):\n",
        "        plt.bar(counter + 1, experiment_data['avg_test_accuracies'][i, j], label=f'DR_in: {dropout_rates_in[i]}, DR_hidden: {dropout_rates_hidden[j]}')\n",
        "        counter += 1\n",
        "\n",
        "max_accuracy = np.max(experiment_data['avg_test_accuracies'])\n",
        "plt.axhline(max_accuracy, color='grey', linestyle='--')\n",
        "plt.title(f'Test Accuracies, Max.: {max_accuracy:.2f}%')\n",
        "plt.xlabel('Experiment Run (indices)')\n",
        "plt.xticks([(n + 1) for n in range(10)], [(n + 1) for n in range(10)])\n",
        "plt.ylabel('Accuracy (in %)')\n",
        "plt.ylim([70, 100])\n",
        "plt.grid()\n",
        "plt.legend(loc='center right', bbox_to_anchor=(1.3, 0.5), fancybox=True, shadow=True, ncol=1)\n",
        "\n",
        "counter = 0\n",
        "plt.subplot(2, 1, 2)\n",
        "for i in range(experiment_data['avg_training_times'].shape[0]):\n",
        "    for j in range(experiment_data['avg_training_times'].shape[1]):\n",
        "        plt.bar(counter + 1, experiment_data['avg_training_times'][i, j], label=f'DR_in: {dropout_rates_in[i]}, DR_hidden: {dropout_rates_hidden[j]}')\n",
        "        counter += 1\n",
        "\n",
        "plt.title(f'Training Times')\n",
        "plt.xlabel('Experiment Run (indices)')\n",
        "plt.xticks([(n + 1) for n in range(10)], [(n + 1) for n in range(10)])\n",
        "plt.ylabel('Time (in sec.)')\n",
        "plt.ylim([20, 60])\n",
        "plt.grid()\n",
        "plt.legend(loc='center right', bbox_to_anchor=(1.3, 0.5), fancybox=True, shadow=True, ncol=1)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('dropout_grid_search')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6hzbdcNxn3Fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Best Test Accuracy inspection\n",
        "best_run_acc = experiment_data['avg_test_accuracies'][0, 0]\n",
        "best_run_time = experiment_data['avg_training_times'][0, 0]\n",
        "print(f'Adam + DropOut: {best_run_acc:.2f}% in {best_run_time:.2f}sec. (per class)')"
      ],
      "metadata": {
        "id": "K0ba_fB6GnK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Batch Normalization**\n",
        "\n",
        "A form of regularization applied to layers inputs, in order to avoid covariance shift, vanishing or exploding gradients.\n",
        "\n",
        "\\begin{align}\n",
        "    \\hat{y} = \\sigma(\\tilde{x}^Tw)\n",
        "\\end{align}\n",
        "\n",
        "with\n",
        "\n",
        "\\begin{align}\n",
        "    \\tilde{x} = \\gamma x + \\beta\n",
        "\\end{align}\n",
        "\n",
        "with $\\gamma$ and $\\beta$ respectively a scaling and shifting coefficient, learned by the model itself during training phase, while $\\tilde{x}$ is a normalized \"raw input\" to the n-Layer.\n",
        "\n",
        "- S. Ioffe, C. Szegedy (2015) - [*Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift*](https://docs.google.com/viewer?url=http%3A%2F%2Fresearch.google.com%2Fpubs%2Farchive%2F43442.pdf)"
      ],
      "metadata": {
        "id": "IaOsje3-8Mk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dynamic Multi-Layer Architecture Class (w. units, activation function, DropOut Rate specification)\n",
        "class binaryClassifier_batchnorm(nn.Module):                                      # nn.Module: base class to inherit from\n",
        "    def __init__(self, n_layers, n_units, act_fun, rate_in, rate_hidden):         # self + attributes (architecture hyper-parameters)\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = nn.ModuleDict()                                             # Dictionary to store Model layers\n",
        "        self.nLayers = n_layers                                                   # Class instance parameter\n",
        "\n",
        "        # Input Layer\n",
        "        self.layers['input'] = nn.Linear(3, n_units)                              # Key 'input' layer specification\n",
        "\n",
        "        # Hidden Layers\n",
        "        self.layers[f'hidden'] = nn.Linear(n_units, n_units)\n",
        "        self.layers[f'batch_norm'] = nn.BatchNorm1d(n_units)\n",
        "\n",
        "        # Output Layer\n",
        "        self.layers['output'] = nn.Linear(n_units, 1)                             # Key 'output' layer specification\n",
        "\n",
        "        # Activation Function\n",
        "        self.actfun = act_fun                                                     # Function string-name attribute association\n",
        "\n",
        "        # Dropout Parameter\n",
        "        self.dr_in = rate_in\n",
        "        self.dr_hidden = rate_hidden\n",
        "\n",
        "        # Weights & Bias initialization\n",
        "        for layer in self.layers.keys():\n",
        "            try:\n",
        "                nn.init.kaiming_normal_(self.layers[layer].weight, mode='fan_in') # Kaiming He - Normal Distributed (ReLU specific)\n",
        "            except:\n",
        "                pass                                                              # Batch_norm Layer can't be initialized\n",
        "        for layer in self.layers.keys():\n",
        "            self.layers[layer].bias.data.fill_(0.)                                # Bias initialization (0.)\n",
        "\n",
        "    # Forward Pass Method\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Activation function object computation\n",
        "        actfun = getattr(torch.nn, self.actfun)\n",
        "\n",
        "        # Input Layer pass                                                        --> Weightening (Dot Product) \"Linear transform\" + \"Non linear function\" transform application\n",
        "        x = actfun()(self.layers['input'](x))\n",
        "        x = F.dropout(x, p=self.dr_in, training=self.training)                    # Activate DropOut only when Model Training == True\n",
        "\n",
        "        # Hidden Layers sequential pass                                           --> Weightening (Dot Product) \"Linear transform\" + \"Non linear function\" transform application\n",
        "        x = self.layers[f'batch_norm'](x)                                         # Apply batch normalization before hidden layer\n",
        "        x = actfun()(self.layers[f'hidden'](x))\n",
        "        x = F.dropout(x, p=self.dr_hidden, training=self.training)                # Same as \"Input pass\"\n",
        "\n",
        "        # Output Layer pass                                                       --> Output Weightening (Dot Product) \"Linear transform\" (Optimizer implement an Output Sigmoid sctivation)\n",
        "        x = self.layers['output'](x)\n",
        "        x = nn.Sigmoid()(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "BTc-SEe9543y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment Parameters\n",
        "epochs = 1000  # For each \"Batch-Set\"\n",
        "iterations = 10  # A total of 10000 Epochs of Training (10x Batch-Sub-Dataset shuffling) --> w. Early Stopping\n",
        "min_tolerance = 0.1 # ...for sub-dataset balancing\n",
        "\n",
        "# Architecture Hyper-Parameters\n",
        "hidden_layer = 1\n",
        "hidden_nodes = 100\n",
        "act_fun = 'ReLU'\n",
        "learning_rates = [0.001, 0.0001, 0.00001]  # Try increasing and reducing actual LR\n",
        "optimizer = 'Adam'\n",
        "\n",
        "# Regularization Hyper-Parameters\n",
        "dropout_rate_in = 0.8\n",
        "dropout_rate_hidden = 0.5"
      ],
      "metadata": {
        "id": "kJZAzNnr72So"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AVG. Time 40min.\n",
        "from time import perf_counter\n",
        "debug=False\n",
        "experiment_results = np.zeros((len(learning_rates), 2))\n",
        "\n",
        "\n",
        "for i in range(len(learning_rates)):\n",
        "    print(f'Experiment {i + 1}: LR: {learning_rates[i]}')\n",
        "\n",
        "    test_accuracies = []  # List of Classes Test Accuracies (Re-initialized for each experiment)\n",
        "    training_times = []  # List of Classes Training Times (Re-initialized for each experiment)\n",
        "\n",
        "    # Experiment Routine\n",
        "    for k in range(len(vowels)):\n",
        "\n",
        "        # Reset Seed\n",
        "        torch.manual_seed(SEED)\n",
        "\n",
        "        # Create Classifier\n",
        "        binary_classifier = binaryClassifier_batchnorm(1, hidden_nodes, act_fun, dropout_rate_in, dropout_rate_hidden)\n",
        "\n",
        "        # Iterated (w. Batch-Sets shuffling) Training\n",
        "        iteration = 0\n",
        "\n",
        "        start_timer = perf_counter()\n",
        "        while iteration < iterations:\n",
        "\n",
        "            # Dataset processing\n",
        "            sub_data, sub_data_labels_bin, _ = one_hot_encoder(sel_class_number=k, dataset=x_data_minmax, debug=debug)\n",
        "            print('----------------------------------')\n",
        "            trainLoader, devLoader, testLoader = train_dev_test_split(sub_data[:, 1:], sub_data_labels_bin, [0.7, 0.15, 0.15], tolerance=min_tolerance, output='Loaders', debug=debug)\n",
        "\n",
        "            # Train/Test Architecture\n",
        "            _, _, _, test_accuracy = mini_batch_train_test(binary_classifier, optimizer, epochs, learning_rates[i], trainLoader, devLoader, testLoader, debug)\n",
        "            print(f'Sub-Net \"{vowels[k]}\" Partial-{iteration + 1} TEST ACCURACY: {test_accuracy:.2f}%')\n",
        "\n",
        "            if test_accuracy > 93.86:  # If specific class instance overshot previous class mean accuracy\n",
        "                iteration += 1\n",
        "                print(f'Training STOP {iteration}--------------------')\n",
        "                break  # Early stop\n",
        "\n",
        "            iteration += 1  # Go to next Batch training iteration\n",
        "\n",
        "        stop_timer = perf_counter()\n",
        "\n",
        "        # Class Outputs append\n",
        "        test_accuracies.append(test_accuracy) # in %\n",
        "        training_times.append(stop_timer - start_timer) # in sec.\n",
        "        print('---------------------------------------------------------------------')\n",
        "\n",
        "    print(f'Classes MEAN ACCURACY: {np.mean(test_accuracies)}%')\n",
        "    print(f'Classes Mean Training Runtime: {np.mean(training_times)}sec.')\n",
        "\n",
        "    experiment_results[i, 0] = np.mean(test_accuracies)  # Average of 12 classes Accuracies\n",
        "    experiment_results[i, 1] = np.mean(training_times)  # Average of 12 classes Training Times\n",
        "\n",
        "    print('------------------------------------------------------------------------------------------------------')\n",
        "\n",
        "# Outputs Save\n",
        "np.savez_compressed(file='./batch_norm_lr',\n",
        "                avg_test_accuracies=experiment_results[:, 0],\n",
        "                avg_training_times=experiment_results[:, 1])"
      ],
      "metadata": {
        "id": "ww2ryw4Z8n4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch Normalization Experiment Plot\n",
        "experiment_data = np.load(file='./batch_norm_lr.npz')\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.suptitle('Dropout + Batch-Norm Regularization Experiment\\n(average results across all classes)\\n')\n",
        "\n",
        "counter = 0\n",
        "plt.subplot(1, 2, 1)\n",
        "for i in range(experiment_data['avg_test_accuracies'].shape[0]):\n",
        "    plt.bar(i + 1, experiment_data['avg_test_accuracies'][i], label=f'LR: {learning_rates[i]}')\n",
        "    counter += 1\n",
        "\n",
        "max_accuracy = np.max(experiment_data['avg_test_accuracies'])\n",
        "plt.axhline(max_accuracy, color='grey', linestyle='--')\n",
        "plt.title(f'Test Accuracies, Max.: {max_accuracy:.2f}%')\n",
        "plt.xlabel('Experiment Run (indices)')\n",
        "plt.xticks([(n + 1) for n in range(3)], [(n + 1) for n in range(3)])\n",
        "plt.ylabel('Accuracy (in %)')\n",
        "plt.ylim([85, 97])\n",
        "plt.grid()\n",
        "plt.legend(loc='best')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "for i in range(experiment_data['avg_training_times'].shape[0]):\n",
        "    plt.bar(i + 1, experiment_data['avg_training_times'][i], label=f'LR: {learning_rates[i]}')\n",
        "\n",
        "plt.title(f'Training Times')\n",
        "plt.xlabel('Experiment Run (indices)')\n",
        "plt.xticks([(n + 1) for n in range(3)], [(n + 1) for n in range(3)])\n",
        "plt.ylabel('Time (in sec.)')\n",
        "plt.ylim([40, 85])\n",
        "plt.grid()\n",
        "plt.legend(loc='best')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('batch_norm_lr')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sdAc56EMJSMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Best Test Accuracy inspection\n",
        "best_run_acc = experiment_data['avg_test_accuracies'][1]\n",
        "best_run_time = experiment_data['avg_training_times'][1]\n",
        "print(f'Adam + DropOut + Batch-Norm: {best_run_acc:.2f}% in {best_run_time:.2f}sec. (per class)')"
      ],
      "metadata": {
        "id": "4O5Y7QaoRHB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **L2 (Ridge) Penalty**\n",
        "\n",
        "$L2$, also called \"*Ridge regression*\" or \"*weight decay*\" regularization it's expressed as:\n",
        "\n",
        "\\begin{align}\n",
        "        J = \\frac{1}{n}\\sum_{i=1}^{n}L(\\hat{y}_i, y_i) + \\lambda||w_i||_2^2\n",
        "\\end{align}\n",
        "\n",
        "where: $||w_i||_2^2 = w^Tw$\n",
        "\n",
        "$\\lambda$ is a scalar coefficient, also called \"regularization parameter/coefficient\" and is usually expressed as:\n",
        "\n",
        "\\begin{align}\n",
        "        \\lambda = \\frac{\\alpha}{2m}\n",
        "\\end{align}\n",
        "\n",
        "where $m$ is the number of weights and $||w||$ represent the vector magnitude (norm) of weights.\n",
        "\n",
        "Generally, we tend to prefer a relatively large value from the left term (the summation) and a relatively small value from the rgularization term in order to minimize cost function adding weights features itself.\n",
        "\n",
        "[*Wikipedia*](https://en.wikipedia.org/wiki/Ridge_regression)"
      ],
      "metadata": {
        "id": "OQzYfYIO94EX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch Training function (w. Adam Optimizer & L2 penalty term) Re-Definition\n",
        "def mini_batch_train_test(model, weight_decay, epochs: int, learning_rate, train_loader, dev_loader, test_loader, debug=False):\n",
        "    \"\"\"\n",
        "    Train & Test an ANN Architecture via Mini-Batch Training (w. Train/Dev/Test PyTorch Loaders) and Adam Backpropagation Optimizer\n",
        "    \"\"\"\n",
        "    # Loss Function initialization\n",
        "    loss_function = nn.BCELoss()\n",
        "\n",
        "    # Optimizer Algorithm initialization\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    # Output list initialization\n",
        "    train_accuracies = []\n",
        "    train_losses = []\n",
        "    dev_accuracies = []\n",
        "\n",
        "    # TRAINING Phase\n",
        "    for epoch in range(epochs):\n",
        "        model.train()  # TRAINING Switch ON\n",
        "\n",
        "        batch_accuracies = []\n",
        "        batch_losses = []\n",
        "\n",
        "        # Training BATCHES Loop\n",
        "        for data_batch, labels_batch in train_loader:\n",
        "            train_predictions = model(data_batch)\n",
        "            train_loss = loss_function(train_predictions.squeeze(), labels_batch.type(torch.int64).float())\n",
        "            batch_losses.append(train_loss.detach())\n",
        "\n",
        "            # Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Accuracy\n",
        "            train_accuracy = 100 * torch.mean(((train_predictions.squeeze() > 0.5) == labels_batch.type(torch.int64).squeeze()).float())\n",
        "\n",
        "            # Batch Stats appending\n",
        "            batch_accuracies.append(train_accuracy.detach())\n",
        "            batch_losses.append(train_loss.detach())\n",
        "\n",
        "        # Training Stats appending\n",
        "        train_accuracies.append(np.mean(batch_accuracies))  # Average of Batch Accuracies = Training step accuracy\n",
        "        train_losses.append(np.mean(batch_losses))  # Average of Batch Losses = Training step Losses\n",
        "\n",
        "        # EVALUATION (Dev) Phase\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            dev_data_batch, dev_labels_batch = next(iter(dev_loader))\n",
        "            dev_predictions = model(dev_data_batch)\n",
        "\n",
        "            dev_accuracy = 100 * torch.mean(((dev_predictions.squeeze() > 0.5) == dev_labels_batch.type(torch.int64).squeeze()).float())\n",
        "\n",
        "            if debug is True:\n",
        "                if epoch % 100 == 0:\n",
        "                    print(f'Epoch {epoch} --> DEV ACCURACY: {dev_accuracy.detach():.3f} %')\n",
        "                    print('--------------------------------')\n",
        "\n",
        "            # Evaluation accuracy appending\n",
        "            dev_accuracies.append(dev_accuracy.detach())\n",
        "\n",
        "    # TEST Phase\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_data_batch, test_labels_batch = next(iter(test_loader))\n",
        "        test_predictions = model(test_data_batch)\n",
        "        test_accuracy = 100 * torch.mean(((test_predictions.squeeze() > 0.5) == test_labels_batch.type(torch.int64).squeeze()).float())\n",
        "\n",
        "        if debug is True:\n",
        "            print(f'TEST ACCURACY: {test_accuracy.detach():.2f} %')\n",
        "            print('--------------------------------------------------------------------')\n",
        "\n",
        "    return train_accuracies, train_losses, dev_accuracies, test_accuracy.detach()"
      ],
      "metadata": {
        "id": "6b8taDnW_fo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment Parameters\n",
        "epochs = 1000  # For each \"Batch-Set\"\n",
        "iterations = 10  # A total of 10000 Epochs of Training (10x Batch-Sub-Dataset shuffling) --> w. Early Stopping\n",
        "min_tolerance = 0.1 # ...for sub-dataset balancing\n",
        "\n",
        "# Architecture Hyper-Parameters\n",
        "hidden_layer = 1\n",
        "hidden_nodes = 100\n",
        "act_fun = 'ReLU'\n",
        "learning_rate = 0.0001\n",
        "optimizer = 'Adam'\n",
        "\n",
        "# Regularization Hyper-Parameters\n",
        "dropout_rate_in = 0.8\n",
        "dropout_rate_hidden = 0.5\n",
        "l2_lambda = np.logspace(-2, -4, num=3, base=10)  # [10^-2, 10^-3, 10^-4]"
      ],
      "metadata": {
        "id": "zatY1tYgAuNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AVG. Time 30min.\n",
        "from time import perf_counter\n",
        "debug=False\n",
        "experiment_results = np.zeros((len(l2_lambda), 2))\n",
        "\n",
        "\n",
        "for i in range(len(l2_lambda)):\n",
        "    print(f'Experiment {i + 1}: L2_Lambda (Weight Decay): {l2_lambda[i]}')\n",
        "\n",
        "    test_accuracies = []  # List of Classes Test Accuracies (Re-initialized for each experiment)\n",
        "    training_times = []  # List of Classes Training Times (Re-initialized for each experiment)\n",
        "\n",
        "    # Experiment Routine\n",
        "    for k in range(len(vowels)):\n",
        "\n",
        "        # Reset Seed\n",
        "        torch.manual_seed(SEED)\n",
        "\n",
        "        # Create Classifier\n",
        "        binary_classifier = binaryClassifier_batchnorm(1, hidden_nodes, act_fun, dropout_rate_in, dropout_rate_hidden)\n",
        "\n",
        "        # Iterated (w. Batch-Sets shuffling) Training\n",
        "        iteration = 0\n",
        "\n",
        "        start_timer = perf_counter()\n",
        "        while iteration < iterations:\n",
        "\n",
        "            # Dataset processing\n",
        "            sub_data, sub_data_labels_bin, _ = one_hot_encoder(sel_class_number=k, dataset=x_data_minmax, debug=debug)\n",
        "            print('----------------------------------')\n",
        "            trainLoader, devLoader, testLoader = train_dev_test_split(sub_data[:, 1:], sub_data_labels_bin, [0.7, 0.15, 0.15], tolerance=min_tolerance, output='Loaders', debug=debug)\n",
        "\n",
        "            # Train/Test Architecture\n",
        "            _, _, _, test_accuracy = mini_batch_train_test(binary_classifier, l2_lambda[i], epochs, learning_rate, trainLoader, devLoader, testLoader, debug)\n",
        "            print(f'Sub-Net \"{vowels[k]}\" Partial-{iteration + 1} TEST ACCURACY: {test_accuracy:.2f}%')\n",
        "\n",
        "            if test_accuracy > 94.96:  # If specific class instance overshot previous class mean accuracy\n",
        "                iteration += 1\n",
        "                print(f'Training STOP {iteration}--------------------')\n",
        "                break  # Early stop\n",
        "\n",
        "            iteration += 1  # Go to next Batch training iteration\n",
        "\n",
        "        stop_timer = perf_counter()\n",
        "\n",
        "        # Class Outputs append\n",
        "        test_accuracies.append(test_accuracy) # in %\n",
        "        training_times.append(stop_timer - start_timer) # in sec.\n",
        "        print('---------------------------------------------------------------------')\n",
        "\n",
        "    print(f'Classes MEAN ACCURACY: {np.mean(test_accuracies)}%')\n",
        "    print(f'Classes Mean Training Runtime: {np.mean(training_times)}sec.')\n",
        "\n",
        "    experiment_results[i, 0] = np.mean(test_accuracies)  # Average of 12 classes Accuracies\n",
        "    experiment_results[i, 1] = np.mean(training_times)  # Average of 12 classes Training Times\n",
        "\n",
        "    print('------------------------------------------------------------------------------------------------------')\n",
        "\n",
        "# Outputs Save\n",
        "np.savez_compressed(file='./L2_grid_search',\n",
        "                avg_test_accuracies=experiment_results[:, 0],\n",
        "                avg_training_times=experiment_results[:, 1])"
      ],
      "metadata": {
        "id": "V1LKD-a1BWBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# L2 Normalization Experiment Plot\n",
        "experiment_data = np.load(file='./L2_grid_search.npz')\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.suptitle('Dropout + Batch-Norm + L2 Norm Experiment\\n(average results across all classes)\\n')\n",
        "\n",
        "counter = 0\n",
        "plt.subplot(1, 2, 1)\n",
        "for i in range(experiment_data['avg_test_accuracies'].shape[0]):\n",
        "    plt.bar(i + 1, experiment_data['avg_test_accuracies'][i], label=f'$\\lambda$: {l2_lambda[i]}')\n",
        "    counter += 1\n",
        "\n",
        "max_accuracy = np.max(experiment_data['avg_test_accuracies'])\n",
        "plt.axhline(max_accuracy, color='grey', linestyle='--')\n",
        "plt.title(f'Test Accuracies, Max.: {max_accuracy:.2f}%')\n",
        "plt.xlabel('Experiment Run (indices)')\n",
        "plt.xticks([(n + 1) for n in range(3)], [(n + 1) for n in range(3)])\n",
        "plt.ylabel('Accuracy (in %)')\n",
        "plt.ylim([80, 100])\n",
        "plt.grid()\n",
        "plt.legend(loc='best')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "for i in range(experiment_data['avg_training_times'].shape[0]):\n",
        "    plt.bar(i + 1, experiment_data['avg_training_times'][i], label=f'$\\lambda$: {l2_lambda[i]}')\n",
        "\n",
        "plt.title(f'Training Times')\n",
        "plt.xlabel('Experiment Run (indices)')\n",
        "plt.xticks([(n + 1) for n in range(3)], [(n + 1) for n in range(3)])\n",
        "plt.ylabel('Time (in sec.)')\n",
        "plt.ylim([40, 70])\n",
        "plt.grid()\n",
        "plt.legend(loc='best')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('L2_grid_search')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JpuWw9LOMFZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Best Test Accuracy inspection\n",
        "best_run_acc = experiment_data['avg_test_accuracies'][2]\n",
        "best_run_time = experiment_data['avg_training_times'][2]\n",
        "print(f'Adam + DropOut + Batch-Norm + L2: {best_run_acc:.2f}% in {best_run_time:.2f}sec. (per class)')"
      ],
      "metadata": {
        "id": "UishBmuobaIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Further improvements*\n",
        "\n",
        "```\n",
        "Multi-Layer Perceptron\n",
        "- Input Layer: 3 features [formant ratios, min-max normalized]\n",
        "- Hidden Layer: 100 units\n",
        "- Output Layer: 1 normalized probability\n",
        "- Learning Rate: 0.0001 (10^-4)\n",
        "- Optimizer: Adam (Adaptive Momentum)\n",
        "\n",
        "- Mini-Batch Training:\n",
        "    . Re-iterated Sub-Dataset Shuffling\n",
        "    . Early Stopping (Test Accuracy driven)\n",
        "    . Batch size = 32\n",
        "\n",
        "- Regularization:\n",
        "    . Weight Decay (L2 Penalty): 0.0001 (10^-4)\n",
        "    . DropOut:\n",
        "        * Input Layer Drop Rate: 0.8\n",
        "        * Hidden Layer Drop Rate: 0.5.\n",
        "    . Batch Normalization\n",
        "```\n",
        "\n",
        "> 1) Repeat each *Hyper-Parameters Grid-Search* narrowing resolution, to better approximate optimum parameters\n",
        ">"
      ],
      "metadata": {
        "id": "75KmuMOEtbCD"
      }
    }
  ]
}