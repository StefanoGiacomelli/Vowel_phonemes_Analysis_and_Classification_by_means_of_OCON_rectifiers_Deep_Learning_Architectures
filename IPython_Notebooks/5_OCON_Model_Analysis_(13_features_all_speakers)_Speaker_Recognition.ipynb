{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTTVdMssxEgE"
      },
      "source": [
        "# ***OCON Model Analysis***\n",
        "*(13-features Complete Dataset - Speaker Recognition)*\n",
        "\n",
        "**Author:** S. Giacomelli\n",
        "\n",
        "**Year:** 2023\n",
        "\n",
        "**Affiliation:** A.Casella Conservatory (student)\n",
        "\n",
        "**Master Degree Thesis**: \"*Vowel phonemes Analysis & Classification by means of OCON rectifiers Deep Learning Architectures*\"\n",
        "\n",
        "**Description:** Python scripts for One-Class-One-Network (OCON) Model analysis and optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0yQDCRgxCbn"
      },
      "outputs": [],
      "source": [
        "# Numerical computations packages/modules\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Dataset processing modules\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Graphic visualization modules\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib_inline\n",
        "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n",
        "\n",
        "# Common Seed initialization\n",
        "SEED = 42  # ... the answer to the ultimate question of Life, the Universe, and Everything... (cit.)\n",
        "\n",
        "# PyTorch Processing Units evaluation\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'AVILABLE Processing Unit: {device.upper()}')\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzyJTDWAVzN0"
      },
      "source": [
        "## **HGCW Dataset**\n",
        "\n",
        "- *Dataset_utils.npz* file read\n",
        "- *One-Hot encoding* definition\n",
        "- *Train/Dev/Test split* definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKqWKW4AVyW6"
      },
      "outputs": [],
      "source": [
        "# Load HGCW 13_features_complete_(w_speaker) Dataset\n",
        "HGCW_dataset_utils = np.load(file='./HGCW_dataset_utils.npz')\n",
        "print('Raw features                    Data shape:', HGCW_dataset_utils['HGCW_raw'].shape)\n",
        "print('Fundamental Normalized features Data shape:', HGCW_dataset_utils['HGCW_fund_norm'].shape)\n",
        "print('MinMax features                 Data shape:', HGCW_dataset_utils['HGCW_minmax'].shape)\n",
        "print('Phoneme Labels                  Data shape:', HGCW_dataset_utils['HGCW_phon_labels'].shape)\n",
        "print('Speaker Labels                  Data shape:', HGCW_dataset_utils['HGCW_spk_labels'].shape)\n",
        "print('Phoneme Classes size            Data shape:', HGCW_dataset_utils['phon_size'].shape)\n",
        "print('Phoneme Classes indices         Data shape:', HGCW_dataset_utils['phon_idx'].shape)\n",
        "print('Phoneme-Speaker coordinates     Data shape:', HGCW_dataset_utils['phon_spk_coords'].shape)  # (Start_Idx, Vow-Spk group size)\n",
        "\n",
        "x_data_raw_np = HGCW_dataset_utils['HGCW_raw']\n",
        "x_data_fund_norm = HGCW_dataset_utils['HGCW_fund_norm']\n",
        "x_data_minmax = HGCW_dataset_utils['HGCW_minmax']\n",
        "y_labels_raw_np = HGCW_dataset_utils['HGCW_phon_labels']\n",
        "z_labels_raw_np = HGCW_dataset_utils['HGCW_spk_labels']\n",
        "vow_size = HGCW_dataset_utils['phon_size']\n",
        "end_idx = HGCW_dataset_utils['phon_idx']\n",
        "phon_spk_coords = HGCW_dataset_utils['phon_spk_coords']\n",
        "\n",
        "# Auxiliary lists\n",
        "vowels = ['ae', 'ah', 'aw', 'eh', 'er', 'ei', 'ih', 'iy', 'oa', 'oo', 'uh', 'uw']  # Vowels list (0 - 11)\n",
        "speakers = ['b', 'g', 'm', 'w']  # Speakers list (0 - 3)\n",
        "colors = ['green', 'blue', 'red']  # ['red', 'saddlebrown', 'darkorange', 'darkgoldenrod', 'gold', 'darkkhaki', 'olive', 'darkgreen', 'steelblue', 'fuchsia', 'indigo', 'black']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fundamental Frequency - Min-Max Scaling\n",
        "print(f'Previous Fundamental Frequency Min: {x_data_minmax[:, 0].min()}, Max: {x_data_minmax[:, 0].max()}')\n",
        "x_data_minmax[:, 0] = (x_data_minmax[:, 0] - x_data_minmax[:, 0].min()) / (x_data_minmax[:, 0].max() - x_data_minmax[:, 0].min())\n",
        "print(f'Actual Fundamental Frequency Min: {x_data_minmax[:, 0].min()}, Max: {x_data_minmax[:, 0].max()}')"
      ],
      "metadata": {
        "id": "uuiwJLTxKgGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Children Labels encoding\n",
        "z_labels_raw_np_alt = np.where(z_labels_raw_np <= 1, 0, z_labels_raw_np - 1)\n",
        "speakers_alt = ['c', 'm', 'w']"
      ],
      "metadata": {
        "id": "vGAZdkOFYHDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encoder(sel_speaker_num=0, dataset=x_data_minmax, spk_labels=z_labels_raw_np_alt, speakers=speakers_alt, debug=False):\n",
        "\n",
        "    if sel_speaker_num < len(speakers):\n",
        "        classes = [n for n in range(len(speakers))]  # Speaker indices\n",
        "        sub_groups_size = []  # Same as vow_size list\n",
        "\n",
        "        sub_data_one = dataset[np.where(spk_labels == sel_speaker_num)[0], :]  # Extract selected speaker sub-dataset\n",
        "        sub_labels_one = np.ones((sub_data_one.shape[0], 1), dtype='int')  # Binarized 1-Label creation\n",
        "        sub_labels_one_orig = np.ones((sub_data_one.shape[0], 1), dtype='int') * sel_speaker_num  # Create a copy of original labels\n",
        "        sub_groups_size.append(sub_data_one.shape[0])\n",
        "        if debug is True:\n",
        "            print(f'Selected Class \"{speakers[sel_speaker_num]}\"-speaker : {sub_data_one.shape[0]} samples')\n",
        "\n",
        "        sub_speakers_size = sub_data_one.shape[0] // 2  # Size for each other speaker sub-group (balancing)\n",
        "        if debug is True:\n",
        "            print(f'Rest Classes size (...each): {sub_speakers_size} samples')\n",
        "\n",
        "        sub_data_zero = np.zeros((sub_speakers_size * 2, sub_data_one.shape[1]))  # Zero-label features dataset initialization\n",
        "        sub_labels_zero_orig = np.zeros((sub_speakers_size * 2, 1), dtype='int')  # Original labels subset array initialization\n",
        "\n",
        "        classes.remove(sel_speaker_num)  # Remove selected speaker index\n",
        "        counter = 0\n",
        "        for i in classes:  # For other speakers...\n",
        "            sub_data_zero_class =  dataset[np.where(spk_labels == i)[0], :]  # Extract speaker subgroup\n",
        "            subset_indices = np.random.choice(np.arange(0, sub_data_zero_class.shape[0], 1), size=sub_speakers_size, replace=False)  # Compute random indices from subgroup array length\n",
        "\n",
        "            sub_data_zero[counter * sub_speakers_size : (counter * sub_speakers_size) + sub_speakers_size, :] = sub_data_zero_class[subset_indices]  # Vertical stacking of random samples from actual speaker subgroup\n",
        "            sub_labels_zero_orig[counter * sub_speakers_size : (counter * sub_speakers_size) + sub_speakers_size, :] = np.ones((sub_data_zero_class[subset_indices].shape[0], 1), dtype='int') * i  # Vertical stacking of a copy of actual subgroup oiriginal labels\n",
        "            sub_groups_size.append(sub_data_zero_class[subset_indices].shape[0])\n",
        "\n",
        "            counter += 1\n",
        "\n",
        "        sub_labels_zero = np.zeros((sub_data_zero.shape[0], 1), dtype='int')  # Binarized 0 Label creation\n",
        "\n",
        "        # Output Matrices\n",
        "        sub_data = np.vstack((sub_data_one, sub_data_zero))  # Vertical stacking 1s and 0s features array\n",
        "        sub_data_labels_bin = np.vstack((sub_labels_one, sub_labels_zero))  # Vertical Stacking 1s and 0s labels array\n",
        "        sub_data_labels_orig = np.vstack((sub_labels_one_orig, sub_labels_zero_orig))  # Vertical stacking original (1-class) and original (0s-class) labels\n",
        "    else:\n",
        "        raise ValueError(f'Invalid Class ID: \"{sel_speaker_num}\" --> It must be less than {len(speakers)}!')\n",
        "\n",
        "    return sub_data, sub_data_labels_bin, sub_data_labels_orig, sub_groups_size\n",
        "\n",
        "# Test Call\n",
        "sel_speaker_num = 0\n",
        "sub_data, sub_data_labels_bin, sub_data_labels_orig, sub_groups_size = one_hot_encoder(sel_speaker_num, dataset=x_data_minmax, spk_labels=z_labels_raw_np_alt, speakers=speakers_alt, debug=True)\n",
        "print(f'Output Array shapes: {sub_data.shape}, {sub_data_labels_bin.shape}, {sub_data_labels_orig.shape}, {len(sub_groups_size)}')"
      ],
      "metadata": {
        "id": "PHie_y5D7j1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sub-Dataset Plot (previous example)\n",
        "classes = [n for n in range(len(speakers_alt))]\n",
        "\n",
        "plt.figure(figsize=(12, 15))\n",
        "plt.suptitle(f'Sub-Dataset (\"{speakers_alt[sel_speaker_num].upper()}\"-speaker - example) One-Hot Encoding')\n",
        "\n",
        "counter = 0\n",
        "for index in range(len(speakers_alt)):\n",
        "    if index == sel_speaker_num:\n",
        "        first_coords = sub_data[:sub_groups_size[0], 1]\n",
        "        second_coords = sub_data[:sub_groups_size[0], 2]\n",
        "        third_coords = sub_data[:sub_groups_size[0], 3]\n",
        "    else:\n",
        "        start_index = sub_groups_size[0] + counter * sub_groups_size[1]\n",
        "        end_index = start_index + sub_groups_size[1]\n",
        "\n",
        "        first_coords = sub_data[start_index: end_index, 1]\n",
        "        second_coords = sub_data[start_index: end_index, 2]\n",
        "        third_coords = sub_data[start_index: end_index, 3]\n",
        "\n",
        "        counter += 1\n",
        "\n",
        "    plt.subplot(3, 2, 1)\n",
        "    plt.title('$1_{st}$ VS $2_{nd}$')\n",
        "    plt.scatter(first_coords, second_coords, marker='o', color=colors[index], label=f'\"{speakers_alt[index]}\"-speaker')\n",
        "    plt.xlabel('$1_{st}$ Formant Ratio')\n",
        "    plt.ylabel('$2_{nd}$ Formant Ratio')\n",
        "    plt.legend(loc='best')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.subplot(3, 2, 3)\n",
        "    plt.title('$1_{st}$ VS $3_{rd}$')\n",
        "    plt.scatter(first_coords, third_coords, marker='o', color=colors[index], label=f'\"{speakers_alt[index]}\"-speaker')\n",
        "    plt.xlabel('$1_{st}$ Formant Ratio')\n",
        "    plt.ylabel('$3_{rd}$ Formant Ratio')\n",
        "    plt.legend(loc='best')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.subplot(3, 2, 5)\n",
        "    plt.title('$2_{nd}$ VS $3_{rd}$')\n",
        "    plt.scatter(second_coords, third_coords, marker='o', color=colors[index], label=f'\"{speakers_alt[index]}\"-speaker')\n",
        "    plt.xlabel('$2_{nd}$ Formant Ratio')\n",
        "    plt.ylabel('$3_{rd}$ Formant Ratio')\n",
        "    plt.legend(loc='best')\n",
        "    plt.grid(True)\n",
        "\n",
        "plt.subplot(3, 2, 2)\n",
        "plt.title('$1_{st}$ VS $2_{nd}$ Binarized')\n",
        "plt.scatter(sub_data[0: sub_groups_size[0], 1], sub_data[0: sub_groups_size[0], 2], color=colors[sel_speaker_num], label=f'\"{speakers_alt[index]}\"-speaker')\n",
        "plt.scatter(sub_data[sub_groups_size[0]: , 1], sub_data[sub_groups_size[0]: , 2], color='grey', label=f'Rest')\n",
        "plt.xlabel('$1_{st}$ Formant Ratio')\n",
        "plt.ylabel('$2_{nd}$ Formant Ratio')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(3, 2, 4)\n",
        "plt.title('$1_{st}$ VS $3_{rd}$ Binarized')\n",
        "plt.scatter(sub_data[0: sub_groups_size[0], 1], sub_data[0: sub_groups_size[0], 3], color=colors[sel_speaker_num], label=f'\"{speakers_alt[index]}\"-speaker')\n",
        "plt.scatter(sub_data[sub_groups_size[0]: , 1], sub_data[sub_groups_size[0]: , 3], color='grey', label=f'Rest')\n",
        "plt.xlabel('$1_{st}$ Formant Ratio')\n",
        "plt.ylabel('$3_{rd}$ Formant Ratio')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(3, 2, 6)\n",
        "plt.title('$2_{nd}$ VS $3_{rd}$ Binarized')\n",
        "plt.scatter(sub_data[0: sub_groups_size[0], 2], sub_data[0: sub_groups_size[0], 3], color=colors[sel_speaker_num], label=f'\"{speakers_alt[index]}\"-speaker')\n",
        "plt.scatter(sub_data[sub_groups_size[0]: , 2], sub_data[sub_groups_size[0]: , 3], color='grey', label=f'Rest')\n",
        "plt.xlabel('$2_{nd}$ Formant Ratio')\n",
        "plt.ylabel('$3_{rd}$ Formant Ratio')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{speakers_alt[sel_speaker_num]}_speaker_one_hot_encoding')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kQasst8ATP_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3tEYZ1TWm3T"
      },
      "outputs": [],
      "source": [
        "# Train/Test split (auxiliary function)\n",
        "def train_test_split_aux(features_dataset, labels_dataset, test_perc, tolerance):\n",
        "    \"\"\"\n",
        "    An auxiliary Train_Test_split function (based on Scikit Learn implementation) w. balance tolerance specification\n",
        "    \"\"\"\n",
        "    test_size = int(test_perc / 100 * len(features_dataset))\n",
        "    train_balance = 0  # Output Training set balance value initialization\n",
        "    test_balance = 0  # Output Testing set balance value initialization\n",
        "\n",
        "    min_tol = np.mean(labels_dataset) - tolerance\n",
        "    max_tol = np.mean(labels_dataset) + tolerance\n",
        "    print(f'Data Balancing  (TARGET = {np.mean(labels_dataset)} +- {tolerance}): ', end='')\n",
        "\n",
        "    while (min_tol >= train_balance or train_balance >= max_tol) or (min_tol >= test_balance or test_balance >= max_tol):\n",
        "        train_data, test_data, train_labels, test_labels = train_test_split(features_dataset, labels_dataset, test_size=test_size, shuffle=True)\n",
        "        train_balance = np.mean(train_labels)\n",
        "        test_balance = np.mean(test_labels)\n",
        "        print('.', end='')\n",
        "    else:\n",
        "        print('OK')\n",
        "\n",
        "    return train_data, test_data, train_labels, test_labels, train_balance, test_balance\n",
        "\n",
        "# Train-Dev-Test split function\n",
        "def train_dev_test_split(x_data, y_labels, split_list, tolerance=0.1, output='Loaders', debug=False):\n",
        "    \"\"\"\n",
        "    Compute a Train, Development (Hold-Out) and a Test set split w. PyTorch Dataset conversion (and eventual Loaders initialization)\n",
        "    \"\"\"\n",
        "    if len(split_list) == 3:\n",
        "        # Train - Dev+Test separation\n",
        "        print('Training --- Devel/Test SPLIT')\n",
        "        train_data, testTMP_data, train_labels, testTMP_labels, _, _ = train_test_split_aux(x_data, y_labels, (split_list[1] * 100) + (split_list[2] * 100), tolerance)\n",
        "        print('----------------------------------')\n",
        "\n",
        "        # Dev - Test separation\n",
        "        print('Devel    ---     Test SPLIT')\n",
        "\n",
        "        split = ((split_list[1] * 100) / np.sum(split_list[1:] * 100)) * 100  # Split in %\n",
        "        dev_data, test_data, dev_labels, test_labels, _, _ = train_test_split_aux(testTMP_data, testTMP_labels, split, tolerance)\n",
        "        print('----------------------------------')\n",
        "\n",
        "        # Tensor Conversion\n",
        "        train_data_tensor = torch.tensor(train_data).float()\n",
        "        train_labels_tensor = torch.tensor(train_labels, dtype=torch.int64).squeeze()\n",
        "        dev_data_tensor = torch.tensor(dev_data).float()\n",
        "        dev_labels_tensor = torch.tensor(dev_labels, dtype=torch.int64).squeeze()\n",
        "        test_data_tensor = torch.tensor(test_data).float()\n",
        "        test_labels_tensor = torch.tensor(test_labels, dtype=torch.int64).squeeze()\n",
        "        if debug is True:\n",
        "            print(f'Training Data        Shape: {train_data.shape}')\n",
        "            print(f'Development Data     Shape: {dev_data.shape}')\n",
        "            print(f'Testing Data         Shape: {test_data.shape}')\n",
        "\n",
        "            # Balance Evaluation\n",
        "            print(f'Training Set       Balance: {np.mean(train_labels)}')\n",
        "            print(f'Development Set    Balance: {np.mean(dev_labels)}')\n",
        "            print(f'Testing Set        Balance: {np.mean(test_labels)}')\n",
        "\n",
        "        if output != 'Loaders':\n",
        "            return train_data_tensor, train_labels_tensor, dev_data_tensor, dev_labels_tensor, test_data_tensor, test_labels_tensor\n",
        "        else:\n",
        "            # PyTorch Dataset Conversion\n",
        "            train_dataset = torch.utils.data.TensorDataset(torch.tensor(train_data).float(), torch.tensor(train_labels, dtype=torch.int64).squeeze())\n",
        "            dev_dataset = torch.utils.data.TensorDataset(torch.tensor(dev_data).float(), torch.tensor(dev_labels, dtype=torch.int64).squeeze())\n",
        "            test_dataset = torch.utils.data.TensorDataset(torch.tensor(test_data).float(), torch.tensor(test_labels, dtype=torch.int64).squeeze())\n",
        "\n",
        "            # DataLoader (Batches) --> Drop-Last control to optimize training\n",
        "            trainLoader = DataLoader(train_dataset, shuffle=False, batch_size = 32, drop_last=True)\n",
        "            devLoader = DataLoader(dev_dataset, shuffle=False, batch_size = dev_dataset.tensors[0].shape[0])\n",
        "            testLoader = DataLoader(test_dataset, shuffle=False, batch_size = test_dataset.tensors[0].shape[0])\n",
        "            if debug is True:\n",
        "                print(f'Training Set    Batch Size: {trainLoader.batch_size}')\n",
        "                print(f'Development Set Batch Size: {devLoader.batch_size}')\n",
        "                print(f'Testing Set     Batch Size: {testLoader.batch_size}')\n",
        "\n",
        "            return trainLoader, devLoader, testLoader\n",
        "    else:\n",
        "        # Train - Test separation\n",
        "        print('Training --- Test    SPLIT')\n",
        "        train_data, test_data, train_labels, test_labels, _, _ = train_test_split_aux(x_data, y_labels, split_list[1] * 100, tolerance, debug=debug)\n",
        "        print('--------------------------')\n",
        "\n",
        "        # Tensor Conversion\n",
        "        train_data_tensor = torch.tensor(train_data).float()\n",
        "        train_labels_tensor = torch.tensor(train_labels, dtype=torch.int64).squeeze()\n",
        "        test_data_tensor = torch.tensor(test_data).float()\n",
        "        test_labels_tensor = torch.tensor(test_labels, dtype=torch.int64).squeeze()\n",
        "        if debug is True:\n",
        "            print(f'Training Data        Shape: {train_data.shape}')\n",
        "            print(f'Testing Data         Shape: {test_data.shape}')\n",
        "\n",
        "            # Balance Evaluation\n",
        "            print(f'Training Set    Balance: {np.mean(train_labels)}')\n",
        "            print(f'Testing Set     Balance: {np.mean(test_labels)}')\n",
        "\n",
        "        if output != 'Loaders':\n",
        "            return train_data_tensor, train_labels_tensor, test_data_tensor, test_labels_tensor\n",
        "        else:\n",
        "            # PyTorch Dataset Conversion\n",
        "            train_dataset = torch.utils.data.TensorDataset(torch.tensor(train_data).float(), torch.tensor(train_labels, dtype=torch.int64).squeeze())\n",
        "            test_dataset = torch.utils.data.TensorDataset(torch.tensor(test_data).float(), torch.tensor(test_labels, dtype=torch.int64).squeeze())\n",
        "\n",
        "            # DataLoader (Batches) --> Drop-Last control to optimize training\n",
        "            trainLoader = DataLoader(train_dataset, shuffle=False, batch_size = 32, drop_last=True)\n",
        "            testLoader = DataLoader(test_dataset, shuffle=False, batch_size = test_dataset.tensors[0].shape[0])\n",
        "            if debug is True:\n",
        "                print(f'Training Set    Batch Size: {trainLoader.batch_size}')\n",
        "                print(f'Testing Set     Batch Size: {testLoader.batch_size}')\n",
        "\n",
        "            return trainLoader, testLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LD85TgYSod5U"
      },
      "source": [
        "## **One-Class Architecture** (Binary Classifier)\n",
        "(see \"*One-Class_Sub-Network_Analysis.ipynb*\")\n",
        "\n",
        "```\n",
        "Multi-Layer Perceptron\n",
        "- Input Layer: 3 features [formant ratios, min-max normalized]\n",
        "- Hidden Layer: 100 units\n",
        "- Output Layer: 1 normalized probability\n",
        "- Learning Rate: 0.0001 (10^-4)\n",
        "- Optimizer: Adam (Adaptive Momentum)\n",
        "\n",
        "- Mini-Batch Training:\n",
        "    . Re-iterated Sub-Dataset Shuffling\n",
        "    . Early Stopping (Test Accuracy driven)\n",
        "    . Batch size = 32\n",
        "\n",
        "- Regularization:\n",
        "    . Weight Decay (L2 Penalty): 0.0001 (10^-4)\n",
        "    . DropOut:\n",
        "        * Input Layer Drop Rate: 0.8\n",
        "        * Hidden Layer Drop Rate: 0.5.\n",
        "    . Batch Normalization\n",
        "```\n",
        "\n",
        "- *MLP Classifier Architecture* class definition\n",
        "- *Mini-Batch Training* function definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYOtpU5Ho0Ky"
      },
      "outputs": [],
      "source": [
        "# Dynamic Multi-Layer Architecture Class (w. units, activation function, batch normalization and dropOut rate specification)\n",
        "class binaryClassifier(nn.Module):                                                # nn.Module: base class to inherit from\n",
        "    def __init__(self, n_units, act_fun, rate_in, rate_hidden, model_name):       # self + attributes (architecture hyper-parameters)\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = nn.ModuleDict()                                             # Dictionary to store Model layers\n",
        "        self.name = model_name\n",
        "\n",
        "        # Input Layer\n",
        "        self.layers['input'] = nn.Linear(13, n_units)                              # Key 'input' layer specification\n",
        "\n",
        "        # Hidden Layer\n",
        "        self.layers[f'hidden'] = nn.Linear(n_units, n_units)\n",
        "        self.layers[f'batch_norm'] = nn.BatchNorm1d(n_units)\n",
        "\n",
        "        # Output Layer\n",
        "        self.layers['output'] = nn.Linear(n_units, 1)                             # Key 'output' layer specification\n",
        "\n",
        "        # Activation Function\n",
        "        self.actfun = act_fun                                                     # Function string-name attribute association\n",
        "\n",
        "        # Dropout Parameter\n",
        "        self.dr_in = rate_in\n",
        "        self.dr_hidden = rate_hidden\n",
        "\n",
        "        # Weights & Bias initialization\n",
        "        for layer in self.layers.keys():\n",
        "            try:\n",
        "                nn.init.kaiming_normal_(self.layers[layer].weight, mode='fan_in') # Kaiming He - Normal Distributed (ReLU specific)\n",
        "            except:\n",
        "                pass                                                              # Batch_norm Layer can't be initialized\n",
        "            self.layers[layer].bias.data.fill_(0.)                                # Bias initialization (0.)\n",
        "\n",
        "    # Forward Pass Method\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Activation function object computation\n",
        "        actfun = getattr(torch.nn, self.actfun)\n",
        "\n",
        "        # Input Layer pass                                                        --> Weightening (Dot Product) \"Linear transform\" + \"Non linear function\" transform application\n",
        "        x = actfun()(self.layers['input'](x))\n",
        "        x = F.dropout(x, p=self.dr_in, training=self.training)                    # Activate DropOut only when Model Training == True\n",
        "\n",
        "        # Single Hidden Layer pass                                                --> Weightening (Dot Product) \"Linear transform\" + \"Non linear function\" transform application\n",
        "        x = self.layers[f'batch_norm'](x)                                         # Apply batch normalization before hidden layer\n",
        "        x = actfun()(self.layers[f'hidden'](x))\n",
        "        x = F.dropout(x, p=self.dr_hidden, training=self.training)                # Same as \"Input pass\"\n",
        "\n",
        "        # Output Layer pass                                                       --> Output Weightening (Dot Product) \"Linear transform\" (Optimizer implement an Output Sigmoid sctivation)\n",
        "        x = self.layers['output'](x)\n",
        "        x = nn.Sigmoid()(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AZCONXJZuBv"
      },
      "outputs": [],
      "source": [
        "# Batch Training function (w. Adam Optimizer & L2 penalty term) Re-Definition\n",
        "def mini_batch_train_test(model, weight_decay, epochs: int, learning_rate, train_loader, dev_loader, test_loader, debug=False):\n",
        "    \"\"\"\n",
        "    Train & Test an ANN Architecture via Mini-Batch Training (w. Train/Dev/Test PyTorch Loaders) and Adam Backpropagation Optimizer\n",
        "    \"\"\"\n",
        "    # Loss Function initialization\n",
        "    loss_function = nn.BCELoss()\n",
        "\n",
        "    # Optimizer Algorithm initialization\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    # Output list initialization\n",
        "    train_accuracies = []\n",
        "    train_losses = []\n",
        "    dev_accuracies = []\n",
        "\n",
        "    # TRAINING Phase\n",
        "    for epoch in range(epochs):\n",
        "        model.train()  # TRAINING Switch ON\n",
        "\n",
        "        batch_accuracies = []\n",
        "        batch_losses = []\n",
        "\n",
        "        # Training BATCHES Loop\n",
        "        for data_batch, labels_batch in train_loader:\n",
        "            train_predictions = model(data_batch)\n",
        "            train_loss = loss_function(train_predictions.squeeze(), labels_batch.type(torch.int64).float())\n",
        "            batch_losses.append(train_loss.detach())\n",
        "\n",
        "            # Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Accuracy\n",
        "            train_accuracy = 100 * torch.mean(((train_predictions.squeeze() > 0.5) == labels_batch.type(torch.int64).squeeze()).float())\n",
        "\n",
        "            # Batch Stats appending\n",
        "            batch_accuracies.append(train_accuracy.detach())\n",
        "            batch_losses.append(train_loss.detach())\n",
        "\n",
        "        # Training Stats appending\n",
        "        train_accuracies.append(np.mean(batch_accuracies))  # Average of Batch Accuracies = Training step accuracy\n",
        "        train_losses.append(np.mean(batch_losses))  # Average of Batch Losses = Training step Losses\n",
        "\n",
        "        # EVALUATION (Dev) Phase\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            dev_data_batch, dev_labels_batch = next(iter(dev_loader))\n",
        "            dev_predictions = model(dev_data_batch)\n",
        "\n",
        "            dev_accuracy = 100 * torch.mean(((dev_predictions.squeeze() > 0.5) == dev_labels_batch.type(torch.int64).squeeze()).float())\n",
        "\n",
        "            if debug is True:\n",
        "                if epoch % 100 == 0:\n",
        "                    print(f'Epoch {epoch} --> DEV ACCURACY: {dev_accuracy.detach():.3f} %')\n",
        "                    print('--------------------------------')\n",
        "\n",
        "            # Evaluation accuracy appending\n",
        "            dev_accuracies.append(dev_accuracy.detach())\n",
        "\n",
        "    # TEST Phase\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_data_batch, test_labels_batch = next(iter(test_loader))\n",
        "        test_predictions = model(test_data_batch)\n",
        "        test_accuracy = 100 * torch.mean(((test_predictions.squeeze() > 0.5) == test_labels_batch.type(torch.int64).squeeze()).float())\n",
        "\n",
        "        if debug is True:\n",
        "            print(f'TEST ACCURACY: {test_accuracy.detach():.2f} %')\n",
        "            print('--------------------------------------------------------------------')\n",
        "\n",
        "    return train_accuracies, train_losses, dev_accuracies, test_accuracy.detach()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JbqjG18pRnn"
      },
      "source": [
        "## **OCON (One-Class-One-Net)** Model\n",
        "\n",
        "Binary classifiers **Parallelization**\n",
        "-  *Classifiers-Bank* function definition\n",
        "    - *Models Parameters* inspection\n",
        "- Classifiers **Sequential** Training & Evaluation\n",
        "- *Models Parameters State Save/Load* function definition\n",
        "\n",
        "---\n",
        "\n",
        "- MaxNet output algorithm\n",
        "- Argmax output algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNdc0cIvsq0T"
      },
      "outputs": [],
      "source": [
        "def OCON_bank(one_class_function, hidden_units, act_fun, dr_in, dr_hidden, classes_list):\n",
        "    \"\"\"\n",
        "    Create a One-Class-One-Network parallelization bank of an input Sub-Network definition\n",
        "    \"\"\"\n",
        "    # Sub-Net names creation\n",
        "    models_name_list = []\n",
        "    for i in range(len(classes_list)):\n",
        "        models_name_list.append(\"{}_{}\".format(classes_list[i], \"subnet\"))  # Class name + _subnet\n",
        "\n",
        "    # Sub-Networks instances creation\n",
        "    sub_nets = []  # Sub Network list initialization\n",
        "\n",
        "    for i in range(len(models_name_list)):\n",
        "\n",
        "        torch.manual_seed(SEED)  # Seed re-initialization\n",
        "\n",
        "        # Sub-Net instance creation\n",
        "        locals()[models_name_list[i]] = one_class_function(hidden_units, act_fun, dr_in, dr_hidden, models_name_list[i])\n",
        "        sub_nets.append(locals()[models_name_list[i]])\n",
        "\n",
        "    return sub_nets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgUnOZ0C-xLe"
      },
      "outputs": [],
      "source": [
        "# Load Architecture Parameters State function\n",
        "def load_model_state(model, state_dict_path):\n",
        "    \"\"\"\n",
        "    Load an existent State Dictionary in a defined model\n",
        "    \"\"\"\n",
        "\n",
        "    model.load_state_dict(torch.load(state_dict_path))\n",
        "    print(f'Loaded Parameters (from \"{state_dict_path}\") into: {model.name}')\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXjVg3GiAk3R"
      },
      "outputs": [],
      "source": [
        "# Build The OCON Model\n",
        "ocon_speakers = OCON_bank(binaryClassifier, 100, 'ReLU', 0.8, 0.5, speakers_alt)  # Best MLP (see \"One-Class_Binary_Classifier_Analysis.ipynb\")\n",
        "\n",
        "# Load Pre-Trained Architectures in a fresh Model instance:\n",
        "#ocon_vowels = OCON_bank(binaryClassifier, 100, 'ReLU', 0.8, 0.5, speaker)  # Best MLP (see \"One-Class_Binary_Classifier_Analysis.ipynb\")\n",
        "#states_path = [\"Trained_models_state/b_subnet_Params.pth\",\n",
        "#               \"Trained_models_state/g_subnet_Params.pth\",\n",
        "#               \"Trained_models_state/m_subnet_Params.pth\",\n",
        "#               \"Trained_models_state/w_subnet_Params.pth\"]\n",
        "#\n",
        "#for i in range(len(ocon_speakers)):\n",
        "#    load_model_state(ocon_speakers[i], states_path[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmE7xerUAcEY"
      },
      "outputs": [],
      "source": [
        "# OCON Evaluation function\n",
        "def OCON_eval(ocon_models_bank, features_dataset: np.ndarray = x_data_minmax, labels: np.ndarray = z_labels_raw_np_alt):\n",
        "    \"\"\"\n",
        "    Evaluate OCON models-bank over an entire dataset\n",
        "    \"\"\"\n",
        "    # Output lists initialization\n",
        "    predictions = []\n",
        "    dist_errors = []\n",
        "    eval_accuracies = []\n",
        "    g_truths = []  # For plotting purpouses\n",
        "\n",
        "    # Evaluate each Sub-Network...\n",
        "    for i in range(len(ocon_models_bank)):\n",
        "        ocon_models_bank[i].eval()  # Put j-esimal Sub-Network in Evaluation Mode\n",
        "        print(f'{ocon_models_bank[i].name.upper()} Evaluation -', end=' ')\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Make predictions\n",
        "            features_data_tensor = torch.tensor(features_dataset).float()\n",
        "            raw_eval_predictions = ocon_models_bank[i](features_data_tensor)\n",
        "\n",
        "            # Create Ground Truths\n",
        "            ground_truth = np.where(labels == i, 1, 0)\n",
        "            ground_truth_tensor = torch.tensor(ground_truth, dtype=torch.int64).squeeze()\n",
        "\n",
        "            # Compute Errors\n",
        "            dist_error = ground_truth_tensor - raw_eval_predictions.detach().squeeze()  # Distances\n",
        "            eval_accuracy = 100 * torch.mean(((raw_eval_predictions.detach().squeeze() > 0.5) == ground_truth_tensor).float())\n",
        "            print(f'Accuracy: {eval_accuracy:.2f}%')\n",
        "\n",
        "        # Outputs append\n",
        "        predictions.append(raw_eval_predictions.detach())\n",
        "        dist_errors.append(dist_error.detach())\n",
        "        eval_accuracies.append(eval_accuracy.detach())\n",
        "\n",
        "        g_truths.append(ground_truth)\n",
        "\n",
        "    return predictions, dist_errors, eval_accuracies, g_truths\n",
        "\n",
        "# For Pre-Trained Models\n",
        "#ocon_predictions, ocon_dist_errors, ocon_eval_accuracies, ocon_g_truths = OCON_eval(ocon_speakers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKW4PuUWc4EB"
      },
      "outputs": [],
      "source": [
        "# Model Parameters State function\n",
        "def model_desc(model):\n",
        "    \"\"\"\n",
        "    Print a Console report of Neural Network Model parameters\n",
        "    \"\"\"\n",
        "    # Parameters Description\n",
        "    print('Params Description:')\n",
        "    trainable_params = 0\n",
        "\n",
        "    for parameter in model.named_parameters():\n",
        "        print(f'Parameter Name      : {parameter[0]}')\n",
        "        print(f'Parameter Weights   : {parameter[1][:]}')\n",
        "        if parameter[1].requires_grad:\n",
        "            print(f'...with {parameter[1].numel()} TRAINABLE parameters')\n",
        "            trainable_params += parameter[1].numel()\n",
        "\n",
        "        print('................................')\n",
        "\n",
        "    print('----------------------------------------------------------------')\n",
        "\n",
        "    # Nodes Count\n",
        "    nodes = 0\n",
        "    for param_name, param_tensor in model.named_parameters():\n",
        "        if 'bias' in param_name:\n",
        "            nodes += len(param_tensor)\n",
        "\n",
        "    print(f'Total Nodes             : {nodes}')\n",
        "    print('----------------------------------------------------------------')\n",
        "\n",
        "# OCON-Model Description\n",
        "for i in range(len(ocon_speakers)):\n",
        "    print(f'OCON \"{ocon_speakers[i].name}\" Classifier STATE')\n",
        "    model_desc(ocon_speakers[i])\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXr1ctCKlJAE"
      },
      "outputs": [],
      "source": [
        "# Training/Eval/Testing Parameters\n",
        "epochs = 1000  # For each \"Data Batch-Set\"\n",
        "loss_breaks = [0.36, 0.08, 0.45]  # loss (for Early Stopping) --> class-specific (empyrical)\n",
        "acc_breaks = [80., 97., 80.]  # % accuracy (for Early Stopping)  --> class-specific (empyrical)\n",
        "min_tolerance = 0.01 # ...for sub-dataset balancing\n",
        "\n",
        "# Outputs Initialization\n",
        "loss_functions = [[] for _ in range(len(ocon_speakers))]\n",
        "training_accuracies = [[] for _ in range(len(ocon_speakers))]\n",
        "evaluation_accuracies = [[] for _ in range(len(ocon_speakers))]\n",
        "test_accuracies = [[] for _ in range(len(ocon_speakers))]\n",
        "training_times = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_w_3q8P1L8i"
      },
      "outputs": [],
      "source": [
        "# OCON Sub-Networks Training\n",
        "from time import perf_counter\n",
        "debug = False\n",
        "\n",
        "for i, speaker in enumerate(speakers_alt):\n",
        "\n",
        "    # Class-specific Early Stopping parameters\n",
        "    loss_break = loss_breaks[i]\n",
        "    acc_break = acc_breaks[i]\n",
        "\n",
        "    print(f'Architecture \"{ocon_speakers[i].name}\" TRAINING PHASE')\n",
        "    print(f'EARLY STOP THRESHOLD: Loss={loss_break}, Accuracy={acc_break}%')\n",
        "\n",
        "    start_timer = perf_counter()\n",
        "    # Iterated (w. Batch-Sets shuffling) Mini-Batch Training\n",
        "    iteration = 0  # Batch Training iteration counter\n",
        "    mean_loss = 1.\n",
        "    test_accuracy = 0.\n",
        "\n",
        "    while (mean_loss > loss_break) or (test_accuracy < acc_break):\n",
        "        # Dataset processing\n",
        "        sub_data, sub_data_labels_bin, _, _ = one_hot_encoder(sel_speaker_num=i, dataset=x_data_minmax, debug=debug)\n",
        "        print('----------------------------------')\n",
        "        trainLoader, devLoader, testLoader = train_dev_test_split(sub_data, sub_data_labels_bin, [0.5, 0.25, 0.25], tolerance=min_tolerance, output='Loaders', debug=debug)\n",
        "\n",
        "        # Train/Test Architecture\n",
        "        train_accuracies, train_losses, dev_accuracies, test_accuracy = mini_batch_train_test(ocon_speakers[i], weight_decay=0.0001, epochs=epochs, learning_rate=0.0001, train_loader=trainLoader, dev_loader=devLoader, test_loader=testLoader, debug=debug)\n",
        "        print(f'Sub-Net \"{speaker.upper()}\" Epoch {(iteration + 1) * epochs} - TEST ACCURACY: {test_accuracy:.2f}%', end=' ')\n",
        "\n",
        "        # Outputs append\n",
        "        loss_functions[i].append(train_losses)\n",
        "        training_accuracies[i].append(train_accuracies)\n",
        "        evaluation_accuracies[i].append(dev_accuracies)\n",
        "        test_accuracies[i].append(test_accuracy)\n",
        "\n",
        "        # Repeating condition evaluation\n",
        "        mean_loss = np.mean(train_losses[-50: ])  # Last 50 losses mean\n",
        "        print(f'- MEAN LOSS: {mean_loss}')\n",
        "\n",
        "        iteration += 1  # Go to next Batch training iteration\n",
        "\n",
        "    print(f'Training STOPPED at iteration {iteration}')\n",
        "    print('--------------------------------------------------------------------')\n",
        "    stop_timer = perf_counter()\n",
        "\n",
        "    print(f'\"{ocon_speakers[i].name}\" Training COMPLETED in {float(stop_timer - start_timer)}sec.')\n",
        "    training_times.append(stop_timer - start_timer)\n",
        "    print('--------------------------------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgJcnktn-bg-"
      },
      "outputs": [],
      "source": [
        "# Graphical smoothing filter\n",
        "def smooth(data, k=100):\n",
        "    \"\"\"\n",
        "    A Convolution LP filter w. interval definition\n",
        "    \"\"\"\n",
        "    return np.convolve(data, np.ones(k) / k, mode='same')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szxOHsZI0tNE"
      },
      "outputs": [],
      "source": [
        "# Training Phase Plots\n",
        "plt.figure(figsize=(12, 5 * 3))\n",
        "\n",
        "# loss_functions, training_accuracies, evaluation_accuracies, test_accuracies, training_times\n",
        "classes = len(ocon_speakers)\n",
        "\n",
        "for i in range(classes):\n",
        "    plt.subplot(classes, 2, (i * 2) + 1)\n",
        "    flat_loss_function = [item for sublist in loss_functions[i] for item in sublist]\n",
        "\n",
        "    plt.plot(smooth(flat_loss_function), 'k-')\n",
        "    plt.axhline(loss_breaks[i], color='r', linestyle='--')\n",
        "    plt.title(f'{ocon_speakers[i].name.upper()} Training Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.xlim([100, len(flat_loss_function) - 100])\n",
        "    plt.ylabel('GT - Predicted diff. (probability)')\n",
        "    plt.grid()\n",
        "\n",
        "    plt.subplot(classes, 2, (i * 2) + 2)\n",
        "    flat_training_accuracy = [item for sublist in training_accuracies[i] for item in sublist]\n",
        "    flat_dev_accuracy = [item for sublist in evaluation_accuracies[i] for item in sublist]\n",
        "    flat_test_accuracy = test_accuracies[i]\n",
        "\n",
        "    plt.plot(smooth(flat_training_accuracy), 'k-', label='Training')\n",
        "    plt.plot(smooth(flat_dev_accuracy), color='grey', label='Development')\n",
        "    if len(flat_test_accuracy) > 1:\n",
        "        plt.plot([(n + 1) * epochs for n in range(len(flat_test_accuracy))], flat_test_accuracy, 'r-', label=f'Test')\n",
        "    else:\n",
        "        plt.axhline(test_accuracy, color='r', linestyle='-', label=f'Test')\n",
        "    plt.title(f'{ocon_speakers[i].name.upper()} Accuracy (after {training_times[i]:.2f}sec.)')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.xlim([100, len(flat_training_accuracy) - 100])\n",
        "    plt.ylabel('Accuracy (in %)')\n",
        "    plt.ylim([40, 101])\n",
        "    plt.grid()\n",
        "    plt.legend(loc='best')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('OCON_training_phase')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub_groups_size"
      ],
      "metadata": {
        "id": "CDTExgVyYOg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaI3Z-_S21yd"
      },
      "outputs": [],
      "source": [
        "# OCON Evaluation\n",
        "\n",
        "# Dataset & Labels Ordering (Plot conveniences)\n",
        "x_data_minmax_ordered = np.zeros((1, x_data_minmax.shape[1]))\n",
        "z_labels_raw_np_alt_ordered = np.zeros((1, 1), dtype='int')\n",
        "data_size = []\n",
        "\n",
        "# Groups Ordering iteration\n",
        "for i in range(len(ocon_speakers)):\n",
        "    indices = np.where(z_labels_raw_np_alt == i)[0]\n",
        "    data_size.append(len(indices))\n",
        "\n",
        "    x_data_minmax_ordered = np.vstack((x_data_minmax_ordered, x_data_minmax[indices]))\n",
        "    z_labels_raw_np_alt_ordered = np.vstack((z_labels_raw_np_alt_ordered, z_labels_raw_np_alt[indices]))\n",
        "\n",
        "x_data_minmax_ordered = np.delete(x_data_minmax_ordered, 0, axis=0)  # Remove 1st initialization null row\n",
        "z_labels_raw_np_alt_ordered = np.delete(z_labels_raw_np_alt_ordered, 0, axis=0)  # Remove 1st initialization null label\n",
        "print(f'Features Dataset Shapes : original {x_data_minmax.shape} VS ordered {x_data_minmax_ordered.shape}')\n",
        "print(f'Labels Dataset Shapes   : original {z_labels_raw_np_alt.shape} VS ordered {z_labels_raw_np_alt_ordered.shape}')\n",
        "\n",
        "ocon_predictions, ocon_dist_errors, ocon_eval_accuracies, ocon_g_truths = OCON_eval(ocon_speakers, features_dataset=x_data_minmax_ordered, labels=z_labels_raw_np_alt_ordered)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_10MmVY9THbt"
      },
      "outputs": [],
      "source": [
        "# Dataset Evaluation Analysis Plot\n",
        "plt.figure(figsize=(18, 5 * len(ocon_speakers)))\n",
        "plot_ticks = []\n",
        "for n in range(len(data_size)):\n",
        "    plot_ticks.append(np.sum(data_size[: n], dtype='int'))\n",
        "\n",
        "iter_idx = plot_ticks + [len(x_data_minmax_ordered)]\n",
        "\n",
        "for i in range(len(ocon_speakers)):\n",
        "    plt.subplot(len(ocon_speakers), 3, (i * 3) + 1)\n",
        "    plt.plot(ocon_predictions[i], 'k.', label='Raw Predictions')\n",
        "    plt.plot(ocon_g_truths[i], 'rx', label='Ground Truths')\n",
        "    plt.axhline(0.5, linestyle='--', color='grey')\n",
        "    plt.title(f'{ocon_speakers[i].name.upper()} Predictions Accuracy: {ocon_eval_accuracies[i]:.2f}%')\n",
        "    plt.xlabel('Data (Indices)')\n",
        "    plt.xticks(plot_ticks, speakers_alt)\n",
        "    plt.ylabel('Normalized Probability')\n",
        "    plt.grid()\n",
        "    plt.legend(loc='best')\n",
        "\n",
        "    plt.subplot(len(ocon_speakers), 3, (i * 3) + 2)\n",
        "    plt.plot(ocon_dist_errors[i], 'k')\n",
        "    plt.title(f'Predicted to Measured Error')\n",
        "    plt.xlabel('Data (Indices)')\n",
        "    plt.xticks(plot_ticks, speakers_alt)\n",
        "    plt.ylabel('Normalized Probability Error')\n",
        "    plt.ylim([-1.1, 1.1])\n",
        "    plt.grid()\n",
        "\n",
        "    plt.subplot(len(ocon_speakers), 3, (i * 3) + 3)\n",
        "\n",
        "    # Predictions list processing\n",
        "    predictions_temp = ocon_predictions[i]\n",
        "    class_predictions = [item for sublist in predictions_temp for item in sublist]  # Turn a list of lists in a single list (of tensors)\n",
        "    for j in range(len(class_predictions)):  # Turn a list of tensors of one variable in a list of scalars (item() method)\n",
        "        class_predictions[j] = class_predictions[j].item()\n",
        "\n",
        "    # Positives & False-Positives extraction\n",
        "    positives = []\n",
        "    for w in range(len(speakers_alt)):\n",
        "        num = (np.array(class_predictions[iter_idx[w]: iter_idx[w + 1]]) > 0.5).sum()\n",
        "        positives.append(num)\n",
        "\n",
        "    plt.bar(np.arange(len(speakers_alt)), positives, color='k')\n",
        "    plt.title(f'\"{speakers_alt[i]}\" Positive Probabilities Distribution')\n",
        "    plt.xlabel('Normalized Probabilities')\n",
        "    plt.ylabel('Occurences')\n",
        "    plt.xticks([n for n in range(3)], speakers_alt)\n",
        "    plt.grid()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('OCON_bank_evaluation')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uiLL--SR48_"
      },
      "outputs": [],
      "source": [
        "# Model Parameters Save/Load functions\n",
        "from pathlib import Path\n",
        "\n",
        "def save_model_state(model, folder_name: str = \"Trained_models_state\"):\n",
        "    \"\"\"\n",
        "    Save Pre-Trained model parameters in a State Dictionary\n",
        "    \"\"\"\n",
        "\n",
        "    MODEL_PATH = Path(folder_name)  # Placed in root\n",
        "    MODEL_PATH.mkdir(parents=True, exist_ok=True)  # Pre-existing folder (w. same name) monitoring\n",
        "    MODEL_NAME = '{}_{}'.format(model.name, \"Params.pth\")\n",
        "    MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "    print(f\"Saving {model.name} Parameters in: {MODEL_SAVE_PATH}\")\n",
        "    torch.save(obj=model.state_dict(), f=MODEL_SAVE_PATH)\n",
        "\n",
        "    return MODEL_SAVE_PATH\n",
        "\n",
        "# Save Pre-Trained Models-bank\n",
        "states_path = []  # Path for each model parameters state\n",
        "for i in range(len(ocon_speakers)):\n",
        "    state_path = save_model_state(ocon_speakers[i])\n",
        "    states_path.append(state_path)\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iykkdli0RrhE"
      },
      "source": [
        "### Output **Maxnet Algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpKJjLewcMGY"
      },
      "outputs": [],
      "source": [
        "# OCON \"MaxNet\" Architecture (Weightening + Non Linearity apply)\n",
        "class OCON_MaxNet(nn.Module):                                             # nn.Module: base class to inherit from\n",
        "    def __init__(self, n_units, act_fun, eps):                                 # self + attributes (architecture hyper-parameters)\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = nn.ModuleDict()                                     # Dictionary to store Model layers\n",
        "        self.eps_weight = eps\n",
        "\n",
        "        # MaxNet Layer\n",
        "        self.layers['MAXNET'] = nn.Linear(n_units, n_units)               # Key 'MaxNet' layer specification\n",
        "\n",
        "        # Weights & Bias initialization\n",
        "        self.layers['MAXNET'].weight.data.fill_(self.eps_weight)\n",
        "        for i in range(n_units):\n",
        "            self.layers['MAXNET'].weight[i][i].data.fill_(1.)  # Self Weight = 1\n",
        "\n",
        "        self.layers['MAXNET'].bias.data.fill_(0.)\n",
        "\n",
        "        # Activation Function\n",
        "        self.actfun = act_fun  # Function string-name attribute association\n",
        "\n",
        "    # Forward Pass Method\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Activation function object computation\n",
        "        actfun = getattr(torch.nn, self.actfun)\n",
        "\n",
        "        # Maxnet Layer pass                                               --> Output Weightening (Dot Product) \"Linear transform\" + Non Linearity Activation Function\n",
        "        x = actfun()(self.layers['MAXNET'](x.squeeze().float()))\n",
        "\n",
        "        # Self\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qxXQ2eBvKry"
      },
      "outputs": [],
      "source": [
        "# Build OCON MaxNetwork Architecture\n",
        "torch.manual_seed(SEED)\n",
        "ocon_maxnet = OCON_MaxNet(n_units=3, act_fun='ReLU', eps=0.25)\n",
        "\n",
        "# MaxNet & Sub-Networks Parameters\n",
        "print('OCON MaxNet STATE')\n",
        "model_desc(ocon_maxnet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FC4B4Dajq_Ih"
      },
      "outputs": [],
      "source": [
        "def maxnet_algo(maxnet_function, n_units, act_fun, eps, input_array):\n",
        "    \"\"\"\n",
        "    MaxNet Re-iteration algorithm for Maximum Value retrieving from an input array\n",
        "    \"\"\"\n",
        "    non_zero_outs = np.count_nonzero(input_array)  # Non Zero Values initialization\n",
        "    maxnet_in = torch.from_numpy(input_array)  # MaxNet Input Tensor initialization\n",
        "\n",
        "    results = []  # Results initialization\n",
        "\n",
        "    counter = 0\n",
        "    while non_zero_outs != 1:\n",
        "        counter += 1\n",
        "\n",
        "        # Create the MaxNet\n",
        "        torch.manual_seed(SEED)  # Redundant\n",
        "        maxnet = maxnet_function(n_units = n_units, act_fun = act_fun, eps = eps)\n",
        "\n",
        "        # Compute Forward Pass\n",
        "        results = maxnet(maxnet_in)\n",
        "\n",
        "        # Non_zero outputs & Maxnet Input Update\n",
        "        non_zero_outs = np.count_nonzero(results.detach().numpy())\n",
        "        maxnet_in = results.detach()  # Save results for next iteration\n",
        "\n",
        "    print(f'Maximum Value found in {counter} iterations')\n",
        "    return np.argmax(results.detach().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2Bx_2o3xYqA"
      },
      "outputs": [],
      "source": [
        "# MaxNet on Sub-Networks predictions\n",
        "ocon_predictions_prob = np.zeros((len(ocon_predictions), x_data_minmax_ordered.shape[0]))  # NumPy predictions matrix (12 * 1617)\n",
        "\n",
        "# Convert from List of Tensors to 2D NumPy Array\n",
        "for i in range(len(ocon_predictions)):\n",
        "    ocon_predictions_prob[i, :] = ocon_predictions[i].detach().squeeze().numpy()\n",
        "\n",
        "maxnet_class_predictions = []  # Classes Outputs list initialization\n",
        "# MaxNet application\n",
        "for i in range(x_data_minmax.shape[0]):\n",
        "    print(f'Dataset Sample({i + 1}) Class Evaluation')\n",
        "\n",
        "    samp_predictions = ocon_predictions_prob[:, i]  # Array of 12 predictions for each Dataset sample (OCON outputs)\n",
        "    class_prediction = maxnet_algo(OCON_MaxNet, n_units=3, act_fun='ReLU', eps=-0.1, input_array=samp_predictions)  # MaxNet Computation\n",
        "    maxnet_class_predictions.append(class_prediction)  # Result appending\n",
        "    print('-----------------------------------------------')\n",
        "\n",
        "maxnet_accuracy = 100 * np.mean((np.array(maxnet_class_predictions).reshape(1597, 1) == z_labels_raw_np_alt_ordered))  # Accuracy computation\n",
        "print(f'Maxnet Output --> Speaker ACCURACY: {maxnet_accuracy}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_j3NrwCATFm"
      },
      "outputs": [],
      "source": [
        "# Argmax on Sub-Networks predictions (...for multiple 1s probabilities MaxNet infinite loops)\n",
        "#ocon_predictions_prob = np.zeros((len(new_ocon_predictions), x_data_minmax.shape[0]))  # NumPy predictions matrix (12 * 1617)\n",
        "#\n",
        "# Convert from List of Tensors to 2D NumPy Array\n",
        "#for i in range(len(new_ocon_predictions)):\n",
        "#    ocon_predictions_prob[i, :] = new_ocon_predictions[i].detach().squeeze().numpy()\n",
        "#\n",
        "#maxnet_class_predictions = np.argmax(ocon_predictions_prob, axis=0)\n",
        "#maxnet_accuracy = 100 * np.mean((np.array(maxnet_class_predictions).reshape(1617, 1) == y_labels_raw_np))  # Accuracy computation\n",
        "#print(f'Maxnet Output ACCURACY: {maxnet_accuracy}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lskWof8qBoQV"
      },
      "outputs": [],
      "source": [
        "# Evaluation Analysis Plot\n",
        "plt.figure(figsize=(30, 5))\n",
        "plt.suptitle(f'OCON Bank + MaxNet Evaluation: {maxnet_accuracy:.0f}%')\n",
        "\n",
        "plot_y_ticks = [n for n in range(len(speakers_alt))]\n",
        "\n",
        "plt.plot(z_labels_raw_np_alt_ordered, 'rs', label='Ground Truths')\n",
        "plt.plot(maxnet_class_predictions, 'k.', label='MAXNET Outputs')\n",
        "plt.xlabel('Dataset samples')\n",
        "plt.xticks(ticks=plot_ticks, labels=speakers_alt)\n",
        "plt.xlim([-10, len(y_labels_raw_np) + 10])\n",
        "plt.ylabel('Labels')\n",
        "plt.yticks(ticks=plot_y_ticks, labels=speakers_alt)\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('OCON_model_evaluation')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}